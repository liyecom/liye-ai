#!/usr/bin/env python3
"""
SellerSprite Data Import Script
================================

Imports SellerSprite keyword data from CSV/XLSX into DuckDB.
Supports batch import of multiple files.

Usage:
    python scripts/import_sellersprite_data.py              # Import all xlsx files
    python scripts/import_sellersprite_data.py -f file.xlsx # Import single file
"""

import sys
import re
from pathlib import Path
from datetime import datetime

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Column mapping (Chinese -> English)
COLUMN_MAPPING = {
    'ÂÖ≥ÈîÆËØç': 'keyword',
    'ÊúàÊêúÁ¥¢Èáè': 'search_volume',
    'Ë¥≠‰π∞Áéá': 'conversion_rate',
    'ÂÖ≥ÈîÆËØçÁøªËØë': 'keyword_translation',
    'ÊµÅÈáèÂç†ÊØî': 'traffic_share',
    'È¢Ñ‰º∞Âë®ÊõùÂÖâÈáè': 'weekly_impressions',
    'Ëá™ÁÑ∂ÊéíÂêç': 'organic_rank',
    'ÂπøÂëäÊéíÂêç': 'ad_rank',
    'ABAÂë®ÊéíÂêç': 'aba_rank',
    'SPR': 'spr',
    'Ê†áÈ¢òÂØÜÂ∫¶': 'title_density',
    'Ë¥≠‰π∞Èáè': 'purchase_count',
    'Â±ïÁ§∫Èáè': 'impressions',
    'ÁÇπÂáªÈáè': 'clicks',
    'ÂïÜÂìÅÊï∞': 'product_count',
    'ÈúÄ‰æõÊØî': 'demand_supply_ratio',
    'ÁÇπÂáªÊÄªÂç†ÊØî': 'click_share',
    'ËΩ¨ÂåñÊÄªÂç†ÊØî': 'conversion_share',
    'PPC‰ª∑Ê†º': 'ppc_bid',
    'Âª∫ËÆÆÁ´û‰ª∑ËåÉÂõ¥': 'suggested_bid_range',
    'ÂâçÂçÅASIN': 'top10_asins',
    'Ëøë7Â§©ÂπøÂëäÁ´ûÂìÅÊï∞': 'ad_competitors_7d',
    'ÂÖ≥ÈîÆËØçÁ±ªÂûã': 'keyword_type',
    'ËΩ¨ÂåñÊïàÊûú': 'conversion_effect',
    'ÊµÅÈáèËØçÁ±ªÂûã': 'traffic_type',
    'Ëá™ÁÑ∂ÊµÅÈáèÂç†ÊØî': 'organic_traffic_share',
    'ÂπøÂëäÊµÅÈáèÂç†ÊØî': 'ad_traffic_share',
    'Ëá™ÁÑ∂ÊéíÂêçÈ°µÁ†Å': 'organic_rank_page',
    'ÂπøÂëäÊéíÂêçÈ°µÁ†Å': 'ad_rank_page',
    'Êõ¥Êñ∞Êó∂Èó¥': 'update_time',
}


def extract_asin_from_filename(filename: str) -> str:
    """Extract ASIN from filename."""
    match = re.search(r'B[0-9A-Z]{9}', filename)
    return match.group(0) if match else None


def read_and_transform_file(file_path: Path) -> 'pd.DataFrame':
    """Read file and transform columns."""
    import pandas as pd

    # Read file
    if file_path.suffix.lower() == '.xlsx':
        df = pd.read_excel(file_path)
    else:
        df = pd.read_csv(file_path)

    # Rename columns
    df = df.rename(columns={k: v for k, v in COLUMN_MAPPING.items() if k in df.columns})

    # Add ASIN from filename
    asin = extract_asin_from_filename(file_path.name)
    if asin and 'asin' not in df.columns:
        df['asin'] = asin

    # Add source file
    df['source_file'] = file_path.name

    return df


def import_sellersprite_data(file_path_arg: str = None):
    """Import SellerSprite data (single file or batch)."""
    print("=" * 60)
    print("SellerSprite Data Import")
    print("=" * 60)

    import pandas as pd
    import duckdb

    db_path = project_root / "src" / "domain" / "data" / "growth_os.duckdb"
    data_dir = project_root / "data" / "sellersprite"

    # Find files
    if file_path_arg:
        file_path = Path(file_path_arg)
        if not file_path.is_absolute():
            file_path = project_root / file_path_arg
        files = [file_path] if file_path.exists() else []
    else:
        files = sorted(data_dir.glob("*.xlsx"))

    if not files:
        print("‚ùå No files found")
        return False

    # Show files
    print(f"\nüìÑ Files to import: {len(files)}")
    for f in files:
        asin = extract_asin_from_filename(f.name)
        print(f"   ‚Ä¢ {f.name} (ASIN: {asin})")

    # Read and merge all files
    print("\nüìã Reading files...")
    all_dfs = []
    for f in files:
        try:
            df = read_and_transform_file(f)
            all_dfs.append(df)
            print(f"   ‚úì {f.name}: {len(df)} rows")
        except Exception as e:
            print(f"   ‚úó {f.name}: {e}")

    if not all_dfs:
        print("‚ùå No data loaded")
        return False

    # Merge all DataFrames
    print("\nüîÑ Merging data...")
    merged_df = pd.concat(all_dfs, ignore_index=True)

    # Add metadata
    merged_df['snapshot_date'] = datetime.now().strftime('%Y-%m-%d')
    merged_df['import_date'] = datetime.now().strftime('%Y-%m-%d')

    print(f"   Total rows: {len(merged_df)}")
    print(f"   Unique ASINs: {merged_df['asin'].nunique()}")

    # Import to DuckDB
    print("\nüîß Importing to DuckDB...")
    conn = duckdb.connect(str(db_path))

    try:
        conn.execute("DROP TABLE IF EXISTS fact_keyword_snapshot")
        conn.register('merged_df', merged_df)
        conn.execute("CREATE TABLE fact_keyword_snapshot AS SELECT * FROM merged_df")

        # Verify
        count = conn.execute("SELECT COUNT(*) FROM fact_keyword_snapshot").fetchone()[0]
        asins = conn.execute("SELECT DISTINCT asin FROM fact_keyword_snapshot").fetchdf()

        print(f"\n‚úÖ Imported {count} rows")
        print(f"\nüìä ASINs in database:")
        for asin in asins['asin'].tolist():
            asin_count = conn.execute(f"SELECT COUNT(*) FROM fact_keyword_snapshot WHERE asin = '{asin}'").fetchone()[0]
            print(f"   ‚Ä¢ {asin}: {asin_count} keywords")

        # Sample
        print("\nüìã Sample data:")
        sample = conn.execute("""
            SELECT asin, keyword, search_volume, conversion_rate
            FROM fact_keyword_snapshot
            ORDER BY TRY_CAST(search_volume AS DOUBLE) DESC NULLS LAST
            LIMIT 5
        """).fetchdf()
        print(sample)

        print("\n" + "=" * 60)
        print("‚úÖ Import Complete!")
        print("=" * 60)
        return True

    except Exception as e:
        print(f"‚ùå Import failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        conn.close()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Import SellerSprite data")
    parser.add_argument("--file", "-f", type=str, help="Single file to import")
    args = parser.parse_args()

    success = import_sellersprite_data(args.file)
    sys.exit(0 if success else 1)
