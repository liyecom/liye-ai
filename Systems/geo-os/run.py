#!/usr/bin/env python3
"""
GEO OS v0.1 - Main Entry Point
çŸ¥è¯†å¼•æ“ä¸»å…¥å£

Usage:
    python run.py                    # å¤„ç†é»˜è®¤æ•°æ®æº
    python run.py --dry-run          # å¹²è¿è¡Œæ¨¡å¼
    python run.py --source sample    # æŒ‡å®šæ•°æ®æº
"""

import argparse
import yaml
from pathlib import Path
from datetime import datetime
import sys

from ingestion.normalize import normalize
from processing.chunk import chunk_documents
from processing.extract import extract_structure
from outputs.export_json import export_units


def load_config(source_name='shengcai'):
    """
    åŠ è½½é…ç½®æ–‡ä»¶

    Args:
        source_name: æ•°æ®æºåç§°

    Returns:
        é…ç½®å­—å…¸
    """
    config_path = Path(__file__).parent / 'config/geo.yaml'

    with open(config_path) as f:
        config = yaml.safe_load(f)

    # å±•å¼€è·¯å¾„ï¼Œæ›¿æ¢ ~ ä¸ºç”¨æˆ·ä¸»ç›®å½•ï¼Œæ›¿æ¢ {source} å ä½ç¬¦
    for key in ['source', 'processed', 'exports', 'logs']:
        path_str = config['paths'][key]
        # æ›¿æ¢æ•°æ®æºåç§°å ä½ç¬¦ï¼ˆæ”¯æŒä¸¤ç§æ ¼å¼ï¼‰
        path_str = path_str.replace('{source}', source_name)
        path_str = path_str.replace('shengcai', source_name)
        config['paths'][key] = Path(path_str).expanduser()

    return config


def setup_logging(config):
    """
    è®¾ç½®æ—¥å¿—

    Args:
        config: é…ç½®å­—å…¸

    Returns:
        æ—¥å¿—æ–‡ä»¶è·¯å¾„
    """
    log_file = config['paths']['logs'] / f"geo_run_{datetime.now():%Y%m%d_%H%M%S}.log"
    log_file.parent.mkdir(parents=True, exist_ok=True)

    # ç®€å•æ—¥å¿—ï¼šå°†è¾“å‡ºåŒæ—¶å†™å…¥æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œæš‚æ—¶ä¸å®ç°å¤æ‚æ—¥å¿—ï¼‰
    return log_file


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='GEO OS v0.1 - Knowledge Engine')
    parser.add_argument('--dry-run', action='store_true', help='Dry run mode (ä¸å®é™…æ‰§è¡Œ)')
    parser.add_argument('--source', default='shengcai', help='Source name (æ•°æ®æºåç§°)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')
    args = parser.parse_args()

    print("=" * 60)
    print("GEO OS v0.1 - Knowledge Engine")
    print("=" * 60)
    print(f"Source: {args.source}")
    print(f"Dry run: {args.dry_run}")
    print(f"Verbose: {args.verbose}")
    print()

    # åŠ è½½é…ç½®
    try:
        config = load_config(args.source)
        log_file = setup_logging(config)
        print(f"ğŸ“ Config loaded: {config['paths']['source']}")
        print(f"ğŸ“ Log file: {log_file}")
        print()
    except Exception as e:
        print(f"âŒ Error loading config: {e}")
        sys.exit(1)

    # æ‰§è¡Œpipeline
    start_time = datetime.now()
    results = {}

    try:
        # Step 1: Normalize
        print("\n" + "=" * 60)
        print("Step 1/4: Normalizing documents")
        print("=" * 60)
        results['normalize'] = normalize(config, dry_run=args.dry_run)

        # Step 2: Chunk
        print("\n" + "=" * 60)
        print("Step 2/4: Chunking documents")
        print("=" * 60)
        results['chunk'] = chunk_documents(config, dry_run=args.dry_run)

        # Step 3: Extract
        print("\n" + "=" * 60)
        print("Step 3/4: Extracting structure")
        print("=" * 60)
        results['extract'] = extract_structure(config, dry_run=args.dry_run)

        # Step 4: Export
        print("\n" + "=" * 60)
        print("Step 4/4: Exporting to JSON")
        print("=" * 60)
        results['export'] = export_units(config, dry_run=args.dry_run)

        # æ€»ç»“
        elapsed = datetime.now() - start_time
        print("\n" + "=" * 60)
        print("âœ… GEO OS Pipeline Completed Successfully")
        print("=" * 60)
        print(f"â±ï¸  Total time: {elapsed.total_seconds():.1f} seconds")
        print()
        print("ğŸ“Š Results Summary:")

        if 'normalize' in results:
            norm = results['normalize']
            print(f"   Normalize:")
            print(f"      Files found: {norm.get('files_found', 0)}")
            print(f"      Processed: {norm.get('files_processed', 0)}")
            print(f"      Skipped: {norm.get('files_skipped', 0)}")
            print(f"      Failed: {norm.get('files_failed', 0)}")

        if 'chunk' in results:
            chunk = results['chunk']
            print(f"   Chunk:")
            print(f"      Files found: {chunk.get('files_found', 0)}")
            print(f"      Chunks created: {chunk.get('chunks_created', 0)}")

        if 'extract' in results:
            extract = results['extract']
            print(f"   Extract:")
            print(f"      Units created: {extract.get('units_created', 0)}")
            print(f"      With headings: {extract.get('units_with_headings', 0)}")
            print(f"      With bullets: {extract.get('units_with_bullets', 0)}")

        if 'export' in results:
            export = results['export']
            print(f"   Export:")
            print(f"      Units exported: {export.get('units_exported', 0)}")
            print(f"      File size: {export.get('file_size_mb', 0):.2f} MB")
            print(f"      Output: {export.get('output_file', 'N/A')}")

    except Exception as e:
        print(f"\nâŒ Pipeline failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
