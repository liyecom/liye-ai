#!/usr/bin/env python3
"""
ç›´æ¥ä½¿ç”¨åŸå§‹çŸ¥è¯†åº“ä¸­çš„å®Œæ•´æ–‡æ¡£ï¼Œæ›¿æ¢ GEO OS ç”Ÿæˆçš„ç¢ç‰‡åŒ–å†…å®¹
"""

import json
import os
import shutil
from pathlib import Path
from datetime import datetime


def find_complete_documents(base_dir: Path) -> list:
    """æ‰¾åˆ°æ‰€æœ‰å®Œæ•´çš„ Markdown æ–‡æ¡£"""
    print(f"ğŸ” æ‰«æåŸå§‹çŸ¥è¯†åº“: {base_dir}")

    all_md_files = list(base_dir.rglob('*.md'))
    complete_docs = []

    for file_path in all_md_files:
        # ç»Ÿè®¡æ–‡ä»¶å¤§å°å’Œå†…å®¹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # è¿‡æ»¤æ¡ä»¶
            char_count = len(content)

            # åˆç†çš„æ–‡ç« é•¿åº¦ï¼š1000-100000 å­—ç¬¦ï¼ˆçº¦ 500-50000 ä¸­æ–‡å­—ï¼‰
            # å¤ªçŸ­çš„æ˜¯ç‰‡æ®µï¼Œå¤ªé•¿çš„æ˜¯æ•°æ®è¡¨
            if char_count < 1000 or char_count > 100000:
                continue

            # æ’é™¤çº¯åˆ—è¡¨æ–‡ä»¶ï¼ˆå¦‚é‚®ç®±åˆ—è¡¨ã€å…³é”®è¯æ•°æ®ï¼‰
            if 'é‚®ç®±' in file_path.name or 'email' in file_path.name.lower():
                continue
            if 'å…³é”®è¯' in file_path.name or 'keywords' in file_path.name.lower():
                continue
            if 'é€‰å“' in file_path.name and char_count > 50000:
                # è¶…å¤§é€‰å“æ•°æ®è¡¨
                continue

            # æ’é™¤ç´¢å¼•æ–‡ä»¶
            if 'README' in file_path.name:
                # README å¯èƒ½æœ‰ä»·å€¼ï¼Œå•ç‹¬æ£€æŸ¥
                if char_count < 1000:
                    continue

            complete_docs.append({
                'path': file_path,
                'relative_path': file_path.relative_to(base_dir),
                'name': file_path.name,
                'char_count': char_count,
                'category': file_path.parent.name,
            })

        except Exception as e:
            print(f"   âš ï¸  æ— æ³•è¯»å–: {file_path.name} - {e}")
            continue

    # æŒ‰å­—ç¬¦æ•°æ’åº
    complete_docs.sort(key=lambda x: x['char_count'], reverse=True)

    return complete_docs


def copy_to_astro(docs: list, target_dir: Path):
    """å¤åˆ¶æ–‡æ¡£åˆ° Astro é¡¹ç›®"""
    target_dir.mkdir(parents=True, exist_ok=True)

    # æ¸…ç©ºç›®æ ‡ç›®å½•
    for file in target_dir.glob('*.md'):
        file.unlink()

    print(f"\\nğŸ“‹ å‡†å¤‡å¤åˆ¶ {len(docs)} ä¸ªæ–‡æ¡£åˆ° Astro é¡¹ç›®...")

    copied = []
    for doc in docs:
        source = doc['path']
        # ä½¿ç”¨åŸå§‹æ–‡ä»¶å
        target = target_dir / doc['name']

        # å¦‚æœæ–‡ä»¶åå†²çªï¼Œæ·»åŠ æ•°å­—åç¼€
        counter = 1
        while target.exists():
            stem = doc['name'].replace('.md', '')
            target = target_dir / f"{stem}-{counter}.md"
            counter += 1

        shutil.copy2(source, target)
        copied.append({
            'source': str(doc['relative_path']),
            'target': target.name,
            'char_count': doc['char_count'],
            'category': doc['category'],
        })

    return copied


def main():
    # åŸå§‹çŸ¥è¯†åº“è·¯å¾„
    amazon_kb = Path.home() / 'documents/CrossBorder/Amazon'

    # Astro é¡¹ç›®è·¯å¾„
    astro_posts = Path.home() / 'github/liye_os/websites/amazon-optimization/src/content/posts'

    print("ğŸš€ æå–åŸå§‹å®Œæ•´æ–‡æ¡£æ›¿æ¢ GEO OS ç¢ç‰‡\\n")

    # 1. æ‰¾åˆ°æ‰€æœ‰å®Œæ•´æ–‡æ¡£
    complete_docs = find_complete_documents(amazon_kb)

    print(f"\\nâœ… æ‰¾åˆ° {len(complete_docs)} ä¸ªå®Œæ•´æ–‡æ¡£")
    print(f"\\nğŸ“Š æ–‡æ¡£åˆ†ç±»ç»Ÿè®¡ï¼š")

    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    categories = {}
    for doc in complete_docs:
        cat = doc['category']
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(doc)

    for cat, docs in sorted(categories.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"   {cat}: {len(docs)} ç¯‡")

    print(f"\\nâ­ å†…å®¹æœ€ä¸°å¯Œçš„æ–‡æ¡£ï¼ˆå‰ 20ï¼‰ï¼š")
    for i, doc in enumerate(complete_docs[:20], 1):
        print(f"   {i}. {doc['name']} - {doc['char_count']} å­— ({doc['category']})")

    # 2. å¤åˆ¶åˆ° Astro é¡¹ç›®
    copied = copy_to_astro(complete_docs, astro_posts)

    print(f"\\nâœ… å·²å¤åˆ¶ {len(copied)} ä¸ªæ–‡æ¡£åˆ° Astro é¡¹ç›®")

    # 3. ä¿å­˜å¤åˆ¶è®°å½•
    output_file = Path.home() / 'github/liye_os/tools/web-publisher/copied_docs.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(copied, f, ensure_ascii=False, indent=2)

    print(f"\\nğŸ’¾ å¤åˆ¶è®°å½•å·²ä¿å­˜åˆ°: {output_file}")

    # 4. ç»Ÿè®¡
    total_chars = sum(d['char_count'] for d in copied)
    avg_chars = total_chars // len(copied) if copied else 0

    print(f"\\nğŸ“ˆ å†…å®¹ç»Ÿè®¡ï¼š")
    print(f"   æ–‡æ¡£æ•°é‡: {len(copied)}")
    print(f"   æ€»å­—ç¬¦æ•°: {total_chars:,}")
    print(f"   å¹³å‡æ¯ç¯‡: {avg_chars:,} å­—")

    print(f"\\nâš ï¸  ä¸‹ä¸€æ­¥ï¼š")
    print(f"   1. è¿è¡Œ enhance.py ä¸ºè¿™äº›æ–‡æ¡£ç”Ÿæˆ frontmatter")
    print(f"   2. é‡æ–°æ„å»ºç½‘ç«™")


if __name__ == '__main__':
    main()
