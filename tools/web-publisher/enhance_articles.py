#!/usr/bin/env python3
"""
AI æ–‡ç« å¢å¼ºè„šæœ¬ - å°†æ™®é€šæ–‡ç« æå‡ä¸º 10x è´¨é‡
ä»¥"äºšé©¬é€Šé€‰å“å®æˆ˜"æ–‡ç« ä¸ºæ ‡å‡†æ¨¡æ¿
"""

import os
import sys
import json
import re
from pathlib import Path
from datetime import datetime

# æ£€æŸ¥ä¾èµ–
try:
    from anthropic import Anthropic
except ImportError:
    print("âŒ é”™è¯¯ï¼šæœªå®‰è£… anthropic åŒ…")
    print("è¯·è¿è¡Œ: pip install anthropic")
    sys.exit(1)

try:
    from dotenv import load_dotenv
    # åŠ è½½ .env æ–‡ä»¶
    env_path = Path.home() / "github/liye_os/.env"
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    pass  # python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡

# ================================
# é…ç½®
# ================================

API_KEY = os.getenv('ANTHROPIC_API_KEY')
if not API_KEY:
    print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
    print("è¯·è¿è¡Œ: export ANTHROPIC_API_KEY='your-api-key'")
    sys.exit(1)

client = Anthropic(api_key=API_KEY)

# è·¯å¾„é…ç½®
POSTS_DIR = Path("/Users/liye/github/liye_os/websites/amazon-optimization/src/content/posts")
OUTPUT_DIR = POSTS_DIR / "_enhanced"
OUTPUT_DIR.mkdir(exist_ok=True)

# ================================
# æ ‡å‡†æ–‡ç« æ¨¡æ¿ï¼ˆPromptï¼‰
# ================================

ENHANCEMENT_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äºšé©¬é€Šè¿è¥å†…å®¹ç¼–è¾‘ï¼Œæ“…é•¿å°†æŠ€æœ¯æ€§æ–‡ç« è½¬åŒ–ä¸ºå¸å¼•äººçš„å®æˆ˜æ•™ç¨‹ã€‚

# ä»»åŠ¡
å°†ä¸‹é¢çš„åŸå§‹æ–‡ç« æ”¹å†™ä¸º 10x è´¨é‡çš„æ·±åº¦æ•™ç¨‹ï¼Œå‚è€ƒä»¥ä¸‹æ ‡å‡†ï¼š

# è´¨é‡æ ‡å‡†ï¼ˆå‚è€ƒæ–‡ç« ï¼š"äºšé©¬é€Šé€‰å“å®æˆ˜ï¼šç«å“åº—é“ºæ³•30å¤©æ‰¾åˆ°æœˆåˆ©æ¶¦5000ç¾å…ƒäº§å“"ï¼‰

## 1. ç»“æ„è¦æ±‚
- **å¼€å¤´**ï¼šæ ¸å¿ƒæ•°æ®è¡¨æ ¼ï¼ˆæŠ•èµ„å›æŠ¥ç‡ã€æ—¶é—´ã€åˆ©æ¶¦ç­‰ï¼‰
- **ç›®å½•**ï¼š6-8 ä¸ªç« èŠ‚ï¼Œå¯ç›´æ¥è·³è½¬ï¼ˆä½¿ç”¨ `<h2 id="ç« èŠ‚å">` æ ¼å¼ï¼‰
- **ç« èŠ‚åˆ†å¸ƒ**ï¼š
  - ç¬¬ä¸€éƒ¨åˆ†ï¼šç—›ç‚¹/é—®é¢˜ï¼ˆä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªæ–¹æ³•ï¼‰
  - ç¬¬äºŒéƒ¨åˆ†ï¼šå®Œæ•´æµç¨‹ï¼ˆ5-7 ä¸ªæ­¥éª¤ï¼‰
  - ç¬¬ä¸‰éƒ¨åˆ†ï¼šçœŸå®æ¡ˆä¾‹ï¼ˆæ•°æ® + æˆªå›¾æè¿°ï¼‰
  - ç¬¬å››éƒ¨åˆ†ï¼šæ•°æ®å¤ç›˜ï¼ˆæ—¶é—´çº¿ + è¡¨æ ¼ï¼‰
  - ç¬¬äº”éƒ¨åˆ†ï¼šé¿å‘æŒ‡å—ï¼ˆ3-5 ä¸ªå¸¸è§é”™è¯¯ï¼‰
  - ç¬¬å…­éƒ¨åˆ†ï¼šå·¥å…·æ¸…å•ï¼ˆå¿…å¤‡ + å…è´¹æ›¿ä»£ï¼‰

## 2. å†…å®¹è¦æ±‚
- **çœŸå®æ•°æ®**ï¼šå…·ä½“æ•°å­—ï¼ˆä¸è¦"å¤§çº¦"ã€"å¾ˆå¤š"ï¼Œè¦"187 å•"ã€"$4,847"ï¼‰
- **å¯æ“ä½œæ€§**ï¼šæ‰‹æŠŠæ‰‹æ•™å­¦ï¼ˆ"ç‚¹å‡»å“ªé‡Œ"ã€"è¾“å…¥ä»€ä¹ˆ"ã€"å¦‚ä½•ç­›é€‰"ï¼‰
- **è¡¨æ ¼å¯è§†åŒ–**ï¼šæ•°æ®ç”¨è¡¨æ ¼å‘ˆç°ï¼ˆMarkdown è¡¨æ ¼ï¼‰
- **å¯¹æ¯”åˆ†æ**ï¼šå¤±è´¥æ¡ˆä¾‹ vs æˆåŠŸæ¡ˆä¾‹
- **æ—¶é—´çº¿**ï¼šWeek 1-8 è¯¦ç»†è®°å½•
- **å·¥å…·æ¨è**ï¼šå…·ä½“å·¥å…·å + ä»·æ ¼ + åŠŸèƒ½

## 3. å†™ä½œé£æ ¼
- **ç¬¬ä¸€äººç§°**ï¼š"æˆ‘çš„å¤±è´¥å²"ã€"æˆ‘å¦‚ä½•æ“ä½œ"
- **å¯¹è¯æ„Ÿ**ï¼šæé—® + å›ç­”ï¼ˆ"ä¸ºä»€ä¹ˆï¼Ÿå› ä¸º..."ï¼‰
- **ç—›ç‚¹å…ˆè¡Œ**ï¼šå…ˆè®²å¤±è´¥ï¼Œå†è®²æˆåŠŸ
- **æ•°æ®æ”¯æ’‘**ï¼šæ¯ä¸ªç»“è®ºéƒ½æœ‰æ•°æ®
- **å¯å¤åˆ¶æ€§**ï¼šè¯»è€…çœ‹å®Œèƒ½ç«‹å³æ‰§è¡Œ

## 4. Frontmatter è¦æ±‚
ç”Ÿæˆå®Œæ•´çš„ frontmatterï¼š
```yaml
---
title: "æ ‡é¢˜ï¼ˆå¸å¼•ç‚¹å‡»ï¼Œ50 å­—ç¬¦ä»¥å†…ï¼‰"
description: "æè¿°ï¼ˆSEO ä¼˜åŒ–ï¼Œ150 å­—ç¬¦ä»¥å†…ï¼ŒåŒ…å«å…³é”®è¯ï¼‰"
pubDate: 2025-12-27
category: "äºšé©¬é€Šè¿è¥"
keywords: ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3", "å…³é”®è¯4", "å…³é”®è¯5"]
intent: "commercial"  # informational/commercial/transactional
---
```

## 5. å¿…é¡»åŒ…å«çš„å…ƒç´ 
- [ ] å¼€ç¯‡æ•°æ®è¡¨æ ¼ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
- [ ] ç›®å½•ï¼ˆ6-8 ä¸ªç« èŠ‚ï¼Œå¸¦é”šç‚¹ï¼‰
- [ ] è‡³å°‘ 3 ä¸ªæ•°æ®è¡¨æ ¼
- [ ] è‡³å°‘ 1 ä¸ªå¤±è´¥æ¡ˆä¾‹
- [ ] è‡³å°‘ 1 ä¸ªæˆåŠŸæ¡ˆä¾‹
- [ ] å…·ä½“å·¥å…·æ¨èï¼ˆåç§° + ä»·æ ¼ï¼‰
- [ ] å¯å¤åˆ¶çš„æµç¨‹ï¼ˆæ­¥éª¤ 1-Nï¼‰
- [ ] é¿å‘æŒ‡å—ï¼ˆå¸¸è§é”™è¯¯ï¼‰

---

# åŸå§‹æ–‡ç« 

{original_content}

---

# è¾“å‡ºè¦æ±‚

1. **è¾“å‡ºå®Œæ•´çš„ Markdown æ–‡ä»¶**ï¼ˆåŒ…å« frontmatterï¼‰
2. **å­—æ•°è¦æ±‚**ï¼š6,000-10,000 å­—
3. **ç« èŠ‚é”šç‚¹**ï¼šä½¿ç”¨ `<h2 id="ç« èŠ‚å">` æ ¼å¼ï¼ˆæ–¹ä¾¿ç›®å½•è·³è½¬ï¼‰
4. **è¡¨æ ¼**ï¼šè‡³å°‘ 5 ä¸ªæ•°æ®è¡¨æ ¼
5. **å¯æ“ä½œæ€§**ï¼šè¯»è€…çœ‹å®Œèƒ½ç«‹å³æ‰§è¡Œ

# ç‰¹åˆ«æé†’

- ä¸è¦ä½¿ç”¨"æ ¹æ®æ–‡ç« å†…å®¹"ã€"åŸæ–‡æåˆ°"ç­‰å…ƒè¯­è¨€
- ä¸è¦å†™"æœ¬æ–‡å°†ä»‹ç»"ï¼Œç›´æ¥å¼€å§‹
- ä¸è¦ç”¨"æˆ‘ä»¬"ï¼Œç”¨"æˆ‘"
- æ•°æ®è¦å…·ä½“ï¼ˆä¸è¦"å¾ˆå¤š"ï¼Œè¦"187 å•"ï¼‰
- é¿å…ç©ºæ´çš„å»ºè®®ï¼ˆå¦‚"è®¤çœŸåˆ†æ"ï¼‰ï¼Œè¦å…·ä½“æ“ä½œï¼ˆå¦‚"æ‰“å¼€ Jungle Scoutï¼Œç‚¹å‡» Product Databaseï¼Œè®¾ç½®ç­›é€‰æ¡ä»¶ï¼šæœˆé”€é‡ 300-1000"ï¼‰

ç°åœ¨å¼€å§‹æ”¹å†™ï¼š
"""

# ================================
# å·¥å…·å‡½æ•°
# ================================

def should_skip(file_path):
    """åˆ¤æ–­æ˜¯å¦è·³è¿‡æ–‡ä»¶"""
    name = file_path.name

    # è·³è¿‡ README æ–‡ä»¶
    if 'README' in name or name.startswith('_'):
        return True, "README æ–‡ä»¶"

    # è·³è¿‡æ ‡å‡†æ–‡ç« ï¼ˆæ¨¡æ¿ï¼‰
    if 'äºšé©¬é€Šé€‰å“å®æˆ˜ç«å“åº—é“ºæ³•' in name:
        return True, "æ ‡å‡†æ¨¡æ¿æ–‡ç« "

    return False, None

def enhance_article(file_path):
    """å¢å¼ºå•ç¯‡æ–‡ç« """
    print(f"\n{'='*60}")
    print(f"ğŸ“„ å¤„ç†: {file_path.name}")
    print(f"{'='*60}")

    # æ£€æŸ¥æ˜¯å¦è·³è¿‡
    skip, reason = should_skip(file_path)
    if skip:
        print(f"â­ï¸  è·³è¿‡: {reason}")
        return None

    # è¯»å–åŸæ–‡
    print("ğŸ“– è¯»å–åŸæ–‡...")
    with open(file_path, 'r', encoding='utf-8') as f:
        original_content = f.read()

    original_length = len(original_content)
    print(f"   åŸæ–‡é•¿åº¦: {original_length:,} å­—ç¬¦")

    # è°ƒç”¨ Claude API
    try:
        print("ğŸ“¡ è°ƒç”¨ Claude API...")

        message = client.messages.create(
            model="claude-3-5-sonnet-20240620",  # Claude 3.5 Sonnet (ç¨³å®šç‰ˆæœ¬)
            max_tokens=16000,  # å…è®¸é•¿ç¯‡è¾“å‡º
            temperature=0.7,
            messages=[{
                "role": "user",
                "content": ENHANCEMENT_PROMPT.format(original_content=original_content)
            }]
        )

        enhanced_content = message.content[0].text

        # ç»Ÿè®¡
        input_tokens = message.usage.input_tokens
        output_tokens = message.usage.output_tokens
        cost = input_tokens * 0.000003 + output_tokens * 0.000015

        enhanced_length = len(enhanced_content)
        improvement_ratio = enhanced_length / original_length

        print(f"âœ… å¢å¼ºå®Œæˆ")
        print(f"   å¢å¼ºåé•¿åº¦: {enhanced_length:,} å­—ç¬¦")
        print(f"   æ”¹è¿›å€æ•°: {improvement_ratio:.1f}x")
        print(f"   è¾“å…¥ tokens: {input_tokens:,}")
        print(f"   è¾“å‡º tokens: {output_tokens:,}")
        print(f"   æˆæœ¬: ${cost:.4f}")

        # ä¿å­˜å¢å¼ºåçš„æ–‡ç« 
        output_path = OUTPUT_DIR / file_path.name
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(enhanced_content)

        print(f"ğŸ’¾ å·²ä¿å­˜: {output_path}")

        return {
            'file': file_path.name,
            'original_length': original_length,
            'enhanced_length': enhanced_length,
            'improvement_ratio': improvement_ratio,
            'input_tokens': input_tokens,
            'output_tokens': output_tokens,
            'cost': cost,
            'output_path': str(output_path)
        }

    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ AI æ–‡ç« å¢å¼ºè„šæœ¬ - 10x è´¨é‡æå‡")
    print("=" * 60)
    print(f"ğŸ“ è¾“å…¥ç›®å½•: {POSTS_DIR}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print()

    # è·å–æ‰€æœ‰æ–‡ç« 
    md_files = sorted(POSTS_DIR.glob("*.md"))
    total_files = len(md_files)

    print(f"ğŸ“Š æ‰¾åˆ° {total_files} ç¯‡æ–‡ç« ")
    print()

    # è¯¢é—®ç”¨æˆ·
    print("ğŸ¤” é€‰æ‹©æ¨¡å¼:")
    print("  1. æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰ 3 ç¯‡ï¼‰")
    print("  2. å°æ‰¹é‡ï¼ˆåªå¤„ç†å‰ 10 ç¯‡ï¼‰")
    print("  3. æ‰¹é‡æ¨¡å¼ï¼ˆå¤„ç†æ‰€æœ‰æ–‡ç« ï¼‰")
    choice = input("è¯·è¾“å…¥ (1/2/3): ").strip()

    if choice == '1':
        print("\nğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ 3 ç¯‡")
        md_files = md_files[:3]
    elif choice == '2':
        print("\nğŸ“¦ å°æ‰¹é‡æ¨¡å¼ï¼šåªå¤„ç†å‰ 10 ç¯‡")
        md_files = md_files[:10]
    elif choice == '3':
        confirm = input(f"\nâš ï¸  ç¡®è®¤è¦å¤„ç† {total_files} ç¯‡æ–‡ç« å—ï¼Ÿ(y/n): ").strip().lower()
        if confirm != 'y':
            print("âŒ å·²å–æ¶ˆ")
            return
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return

    # é¢„ä¼°æˆæœ¬
    estimated_cost = len(md_files) * 0.15  # å‡è®¾æ¯ç¯‡ $0.15
    print(f"\nğŸ’° é¢„ä¼°æˆæœ¬: ${estimated_cost:.2f}")
    print(f"   (å®é™…æˆæœ¬å–å†³äºæ–‡ç« é•¿åº¦å’Œè¾“å‡ºè´¨é‡)")
    print()

    confirm = input("ç¡®è®¤ç»§ç»­ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("âŒ å·²å–æ¶ˆ")
        return

    # å¤„ç†æ–‡ç« 
    results = []
    total_cost = 0
    skipped = 0

    start_time = datetime.now()

    for i, file_path in enumerate(md_files, 1):
        print(f"\n[{i}/{len(md_files)}]")
        result = enhance_article(file_path)

        if result:
            results.append(result)
            total_cost += result['cost']
        else:
            skipped += 1

    # è®¡ç®—æ€»æ—¶é—´
    elapsed = datetime.now() - start_time

    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
    print("=" * 60)
    print(f"âœ… æˆåŠŸ: {len(results)} ç¯‡")
    print(f"â­ï¸  è·³è¿‡: {skipped} ç¯‡")
    print(f"ğŸ’° æ€»æˆæœ¬: ${total_cost:.2f}")
    print(f"â±ï¸  æ€»è€—æ—¶: {int(elapsed.total_seconds())} ç§’ ({elapsed.total_seconds()/60:.1f} åˆ†é’Ÿ)")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print()

    if results:
        avg_cost = total_cost / len(results)
        avg_improvement = sum(r['improvement_ratio'] for r in results) / len(results)

        print(f"ğŸ“ˆ å¹³å‡æ•°æ®:")
        print(f"   å¹³å‡æˆæœ¬: ${avg_cost:.4f}/ç¯‡")
        print(f"   å¹³å‡æ”¹è¿›: {avg_improvement:.1f}x")
        print()

    # ä¿å­˜ç»Ÿè®¡
    stats_file = OUTPUT_DIR / "_stats.json"
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'total_files': len(md_files),
            'processed': len(results),
            'skipped': skipped,
            'total_cost': total_cost,
            'elapsed_seconds': elapsed.total_seconds(),
            'results': results
        }, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“Š ç»Ÿè®¡æ–‡ä»¶å·²ä¿å­˜: {stats_file}")
    print()
    print("âœ¨ å®Œæˆï¼æ£€æŸ¥ _enhanced/ ç›®å½•æŸ¥çœ‹å¢å¼ºåçš„æ–‡ç« ")

if __name__ == "__main__":
    main()
