#!/usr/bin/env python3
"""
Geo Pipeline - AI å…ƒæ•°æ®å¢å¼ºå±‚
ä½¿ç”¨ Claude API ä¸º units ç”Ÿæˆå®Œæ•´çš„ SEO å…ƒæ•°æ® + è”ç›Ÿè¥é”€å­—æ®µ

ç”¨æ³•ï¼š
    python enhance.py --input /path/to/geo_units.json --output /path/to/enhanced_units.json
    python enhance.py --test  # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ 10 ä¸ª units
"""

import json
import os
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any
import anthropic


# ================================
# é…ç½®
# ================================

CLAUDE_MODEL = "claude-3-5-haiku-20241022"  # Claude 3.5 Haikuï¼ˆæ€§ä»·æ¯”ä¹‹é€‰ï¼‰
MAX_TOKENS = 500
TEMPERATURE = 0.7

# å…ƒæ•°æ®ç”Ÿæˆ Prompt æ¨¡æ¿
PROMPT_TEMPLATE = """è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆç½‘ç«™å…ƒæ•°æ®å’Œè”ç›Ÿè¥é”€æ¨èï¼š

å†…å®¹é¢„è§ˆï¼š
{content_preview}

æºæ–‡ä»¶ï¼š{source_file}

è¯·ç”Ÿæˆï¼ˆä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¿”å›ï¼‰ï¼š
1. title: ç®€æ´çš„æ ‡é¢˜ï¼ˆ50å­—ç¬¦ä»¥å†…ï¼Œå¸å¼•ç‚¹å‡»ï¼‰
2. description: SEOæè¿°ï¼ˆ150å­—ç¬¦ä»¥å†…ï¼ŒåŒ…å«å…³é”®è¯ï¼‰
3. category: åˆ†ç±»ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼šè·¨å¢ƒç”µå•†/AIåº”ç”¨/å‰¯ä¸šåˆ›æ”¶/è¥é”€å¢é•¿/ä¸ªäººæˆé•¿/åˆ›ä¸šæŠ•èµ„ï¼‰
4. keywords: 5ä¸ªSEOå…³é”®è¯ï¼ˆæ•°ç»„ï¼‰
5. slug: URLè·¯å¾„ï¼ˆè‹±æ–‡ï¼Œå°å†™ï¼Œç”¨-åˆ†éš”ï¼Œå¦‚ï¼šhow-to-optimize-amazon-listingï¼‰
6. affiliate_products: æ¨èçš„è”ç›Ÿäº§å“ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼Œå¯å¤šé€‰ï¼‰ï¼š
   - amazon_seller_toolsï¼ˆAmazonå–å®¶å·¥å…·ï¼‰
   - ecommerce_platformsï¼ˆç”µå•†å¹³å°ï¼‰
   - ai_writing_toolsï¼ˆAIå†™ä½œå·¥å…·ï¼‰
   - marketing_softwareï¼ˆè¥é”€è½¯ä»¶ï¼‰
   - online_coursesï¼ˆåœ¨çº¿è¯¾ç¨‹ï¼‰
   - booksï¼ˆç›¸å…³ä¹¦ç±ï¼‰
7. cta_text: Call-to-Actionæ–‡æ¡ˆï¼ˆå¦‚ï¼š"æŸ¥çœ‹æœ€ä½³Amazonå·¥å…·"ï¼‰
8. intent: ç”¨æˆ·æ„å›¾ï¼ˆinformational=çº¯å­¦ä¹ /commercial=æ¯”è¾ƒé€‰æ‹©/transactional=å‡†å¤‡è´­ä¹°ï¼‰

è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼š
{{
  "title": "...",
  "description": "...",
  "category": "...",
  "keywords": ["...", "...", "...", "...", "..."],
  "slug": "...",
  "affiliate_products": ["...", "..."],
  "cta_text": "...",
  "intent": "informational|commercial|transactional"
}}
"""


# ================================
# å·¥å…·å‡½æ•°
# ================================

def load_json(file_path: Path) -> Dict:
    """åŠ è½½ JSON æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_json(data: Dict, file_path: Path, pretty: bool = True):
    """ä¿å­˜ JSON æ–‡ä»¶"""
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        if pretty:
            json.dump(data, f, indent=2, ensure_ascii=False)
        else:
            json.dump(data, f, ensure_ascii=False)


def call_claude_api(content: str, source_file: str, api_key: str) -> Dict:
    """
    è°ƒç”¨ Claude API ç”Ÿæˆå…ƒæ•°æ®

    Args:
        content: unit å†…å®¹
        source_file: æºæ–‡ä»¶è·¯å¾„
        api_key: Anthropic API key

    Returns:
        ç”Ÿæˆçš„å…ƒæ•°æ®å­—å…¸
    """
    client = anthropic.Anthropic(api_key=api_key)

    # æˆªå–å†…å®¹å‰ 400 å­—ç¬¦ä½œä¸ºé¢„è§ˆ
    content_preview = content[:400] if len(content) > 400 else content

    # æ„å»º prompt
    prompt = PROMPT_TEMPLATE.format(
        content_preview=content_preview,
        source_file=source_file
    )

    try:
        # è°ƒç”¨ API
        message = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=MAX_TOKENS,
            temperature=TEMPERATURE,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        # æå–å“åº”
        response_text = message.content[0].text

        # å°è¯•è§£æ JSON
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        metadata = json.loads(response_text)

        return metadata

    except Exception as e:
        print(f"âš ï¸  API è°ƒç”¨å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤å€¼
        return {
            "title": "å¾…ç”Ÿæˆ",
            "description": "å¾…ç”Ÿæˆ",
            "category": "å…¶ä»–",
            "keywords": [],
            "slug": "pending",
            "affiliate_products": [],
            "cta_text": "äº†è§£æ›´å¤š",
            "intent": "informational"
        }


def enhance_unit(unit: Dict, api_key: str, verbose: bool = False) -> Dict:
    """
    å¢å¼ºå•ä¸ª unit

    Args:
        unit: åŸå§‹ unit æ•°æ®
        api_key: Anthropic API key
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        å¢å¼ºåçš„ unit
    """
    if verbose:
        print(f"   å¤„ç†: {unit['id']}")

    # è°ƒç”¨ API ç”Ÿæˆå…ƒæ•°æ®
    metadata = call_claude_api(
        content=unit['content'],
        source_file=unit.get('source_file', 'unknown'),
        api_key=api_key
    )

    # åˆå¹¶åˆ° unit
    enhanced_unit = unit.copy()
    enhanced_unit.update(metadata)

    return enhanced_unit


def load_cache(cache_file: Path) -> Dict:
    """åŠ è½½ç¼“å­˜ï¼ˆå·²å¤„ç†çš„ unitsï¼‰"""
    if cache_file.exists():
        return load_json(cache_file)
    return {}


def save_cache(cache: Dict, cache_file: Path):
    """ä¿å­˜ç¼“å­˜"""
    save_json(cache, cache_file)


# ================================
# ä¸»å‡½æ•°
# ================================

def main():
    parser = argparse.ArgumentParser(description='AI å…ƒæ•°æ®å¢å¼ºå±‚')
    parser.add_argument('--input', type=str, help='è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, help='è¾“å‡º JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--test', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰ 10 ä¸ª unitsï¼‰')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    parser.add_argument('--resume', action='store_true', help='ä»ç¼“å­˜æ¢å¤ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰')

    args = parser.parse_args()

    # é»˜è®¤è·¯å¾„
    if not args.input:
        args.input = str(Path.home() / 'data/exports/shengcai/geo_units_v0.1.json')

    if not args.output:
        args.output = str(Path.home() / 'data/exports/shengcai/enhanced_units.json')

    input_path = Path(args.input)
    output_path = Path(args.output)
    cache_file = output_path.parent / f".{output_path.stem}_cache.json"

    # æ£€æŸ¥ API key
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯·è®¾ç½®ï¼šexport ANTHROPIC_API_KEY='your-api-key'")
        return 1

    # åŠ è½½è¾“å…¥
    print(f"ğŸ“¥ åŠ è½½è¾“å…¥ï¼š{input_path}")
    data = load_json(input_path)
    units = data['units']
    total_units = len(units)

    # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ 10 ä¸ª
    if args.test:
        units = units[:10]
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {len(units)} ä¸ª units")

    # åŠ è½½ç¼“å­˜
    cache = {}
    if args.resume:
        cache = load_cache(cache_file)
        print(f"â™»ï¸  ä»ç¼“å­˜æ¢å¤ï¼šå·²å¤„ç† {len(cache)} ä¸ª units")

    # å¤„ç† units
    print(f"\nğŸš€ å¼€å§‹å¤„ç† {len(units)} ä¸ª units...")
    print(f"   æ¨¡å‹ï¼š{CLAUDE_MODEL}")
    print(f"   é¢„è®¡æˆæœ¬ï¼š${len(units) * 0.004:.2f} (Haiku 3.5: çº¦ 600 tokens è¾“å…¥ + 300 tokens è¾“å‡º)")
    print()

    enhanced_units = []
    processed_count = 0
    skipped_count = 0
    failed_count = 0

    start_time = datetime.now()

    for i, unit in enumerate(units, 1):
        unit_id = unit['id']

        # æ£€æŸ¥ç¼“å­˜
        if unit_id in cache:
            enhanced_units.append(cache[unit_id])
            skipped_count += 1
            if args.verbose:
                print(f"   [{i}/{len(units)}] â­ï¸  è·³è¿‡ï¼ˆå·²ç¼“å­˜ï¼‰: {unit_id}")
            continue

        try:
            # å¢å¼º unit
            enhanced_unit = enhance_unit(unit, api_key, verbose=args.verbose)
            enhanced_units.append(enhanced_unit)

            # æ›´æ–°ç¼“å­˜
            cache[unit_id] = enhanced_unit

            processed_count += 1

            if not args.verbose:
                print(f"   [{i}/{len(units)}] âœ… {unit_id}")

            # æ¯ 10 ä¸ªä¿å­˜ä¸€æ¬¡ç¼“å­˜
            if i % 10 == 0:
                save_cache(cache, cache_file)
                if args.verbose:
                    print(f"   ğŸ’¾ ç¼“å­˜å·²ä¿å­˜ï¼ˆ{i} ä¸ªï¼‰")

        except Exception as e:
            print(f"   [{i}/{len(units)}] âŒ {unit_id}: {e}")
            failed_count += 1

    # æœ€ç»ˆä¿å­˜ç¼“å­˜
    save_cache(cache, cache_file)

    # ç”Ÿæˆè¾“å‡º
    output_data = {
        'version': '0.2.0',
        'enhanced_at': datetime.now().isoformat(),
        'unit_count': len(enhanced_units),
        'source_file': str(input_path),
        'units': enhanced_units
    }

    # ä¿å­˜è¾“å‡º
    print(f"\nğŸ’¾ ä¿å­˜è¾“å‡ºï¼š{output_path}")
    save_json(output_data, output_path)

    # ç»Ÿè®¡
    elapsed = datetime.now() - start_time
    print(f"\nâœ… å¤„ç†å®Œæˆ")
    print(f"   æ€»æ•°ï¼š{len(units)}")
    print(f"   å·²å¤„ç†ï¼š{processed_count}")
    print(f"   è·³è¿‡ï¼ˆç¼“å­˜ï¼‰ï¼š{skipped_count}")
    print(f"   å¤±è´¥ï¼š{failed_count}")
    print(f"   è€—æ—¶ï¼š{elapsed.total_seconds():.1f} ç§’")
    print(f"   è¾“å‡ºï¼š{output_path}")

    return 0


if __name__ == '__main__':
    exit(main())
