#!/usr/bin/env python3
"""
ä¸ºåŸå§‹ Markdown æ–‡æ¡£æ·»åŠ  Astro frontmatter
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime
import anthropic


def extract_existing_frontmatter(content: str) -> tuple:
    """æå–å·²æœ‰çš„ frontmatterï¼ˆå¦‚æœæœ‰ï¼‰"""
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            return parts[1].strip(), parts[2].strip()
    return None, content


def generate_frontmatter(file_path: Path, content: str, api_key: str) -> dict:
    """ä½¿ç”¨ Claude API ç”Ÿæˆ frontmatter"""
    client = anthropic.Anthropic(api_key=api_key)

    # æå–å·²æœ‰ frontmatterï¼ˆå¦‚æœæœ‰ï¼‰
    existing_fm, body = extract_existing_frontmatter(content)

    # åªå–å‰ 2000 å­—ç¬¦ä½œä¸ºé¢„è§ˆ
    preview = body[:2000]

    prompt = f"""è¯·ä¸ºä»¥ä¸‹ Amazon è·¨å¢ƒç”µå•†æ–‡æ¡£ç”Ÿæˆ Astro frontmatterã€‚

æ–‡ä»¶åï¼š{file_path.name}

{f"å·²æœ‰ frontmatterï¼š\\n{existing_fm}\\n" if existing_fm else ""}

å†…å®¹é¢„è§ˆï¼š
{preview}

è¯·ç”Ÿæˆï¼š
1. title: å¸å¼•äººçš„æ ‡é¢˜ï¼ˆ50å­—ç¬¦ä»¥å†…ï¼‰
2. description: SEOæè¿°ï¼ˆ150å­—ç¬¦ä»¥å†…ï¼‰
3. category: åˆ†ç±»ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼šè·¨å¢ƒç”µå•†/å¹¿å‘Šä¼˜åŒ–/é€‰å“ç­–ç•¥/è¿è¥æŠ€å·§/ç«™å¤–æ¨å¹¿/è´¦å·å®‰å…¨/å·¥å…·æ¨¡æ¿ï¼‰
4. keywords: 5ä¸ªSEOå…³é”®è¯ï¼ˆæ•°ç»„ï¼‰
5. affiliateProducts: æ¨èçš„è”ç›Ÿäº§å“ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼Œå¯å¤šé€‰ï¼‰ï¼š
   - amazon_seller_toolsï¼ˆAmazonå–å®¶å·¥å…·ï¼‰
   - marketing_softwareï¼ˆè¥é”€è½¯ä»¶ï¼‰
   - online_coursesï¼ˆåœ¨çº¿è¯¾ç¨‹ï¼‰
6. ctaText: Call-to-Actionæ–‡æ¡ˆ
7. intent: ç”¨æˆ·æ„å›¾ï¼ˆinformational=çº¯å­¦ä¹ /commercial=æ¯”è¾ƒé€‰æ‹©/transactional=å‡†å¤‡è´­ä¹°ï¼‰

è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼š
{{
  "title": "...",
  "description": "...",
  "category": "...",
  "keywords": ["...", "...", ...],
  "affiliateProducts": ["...", "..."],
  "ctaText": "...",
  "intent": "informational|commercial|transactional"
}}"""

    try:
        message = client.messages.create(
            model="claude-3-5-haiku-20241022",
            max_tokens=1000,
            messages=[{"role": "user", "content": prompt}]
        )

        response_text = message.content[0].text.strip()

        # æå– JSON
        json_match = re.search(r'\\{[\\s\\S]*\\}', response_text)
        if json_match:
            metadata = json.loads(json_match.group())
            return metadata
        else:
            print(f"   âš ï¸  æ— æ³•è§£æ JSON: {file_path.name}")
            return None

    except Exception as e:
        print(f"   âŒ API è°ƒç”¨å¤±è´¥: {file_path.name} - {e}")
        return None


def add_frontmatter_to_file(file_path: Path, metadata: dict):
    """ä¸ºæ–‡ä»¶æ·»åŠ  frontmatter"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # ç§»é™¤å·²æœ‰çš„ frontmatterï¼ˆå¦‚æœæœ‰ï¼‰
        _, body = extract_existing_frontmatter(content)

        # ç”Ÿæˆæ–°çš„ frontmatter
        frontmatter = f"""---
title: {metadata['title']}
description: {metadata['description']}
pubDate: {datetime.now().strftime('%Y-%m-%d')}
category: {metadata['category']}
keywords:
"""
        for kw in metadata['keywords']:
            frontmatter += f"  - {kw}\\n"

        if metadata.get('affiliateProducts'):
            frontmatter += "affiliateProducts:\\n"
            for prod in metadata['affiliateProducts']:
                frontmatter += f"  - {prod}\\n"

        frontmatter += f"""ctaText: {metadata.get('ctaText', 'æŸ¥çœ‹æ¨èå·¥å…·')}
intent: {metadata['intent']}
---
"""

        # ç»„åˆæ–°å†…å®¹
        new_content = frontmatter + body

        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return True

    except Exception as e:
        print(f"   âŒ å†™å…¥å¤±è´¥: {file_path.name} - {e}")
        return False


def main():
    posts_dir = Path.home() / 'github/liye_os/websites/amazon-optimization/src/content/posts'
    api_key = os.getenv('ANTHROPIC_API_KEY')

    if not api_key:
        print("âŒ æœªæ‰¾åˆ° ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
        return

    print(f"ğŸš€ ä¸ºåŸå§‹æ–‡æ¡£æ·»åŠ  frontmatter...\\n   ç›®å½•: {posts_dir}\\n")

    md_files = sorted(posts_dir.glob('*.md'))
    total = len(md_files)

    print(f"ğŸ“‹ æ‰¾åˆ° {total} ä¸ªæ–‡æ¡£\\n")

    processed = 0
    failed = 0

    for i, file_path in enumerate(md_files, 1):
        print(f"[{i}/{total}] å¤„ç†: {file_path.name}")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # ç”Ÿæˆ frontmatter
            metadata = generate_frontmatter(file_path, content, api_key)

            if metadata:
                # æ·»åŠ åˆ°æ–‡ä»¶
                if add_frontmatter_to_file(file_path, metadata):
                    processed += 1
                    print(f"   âœ… æˆåŠŸ: {metadata['title']}")
                else:
                    failed += 1
            else:
                failed += 1

        except Exception as e:
            print(f"   âŒ é”™è¯¯: {e}")
            failed += 1

    print(f"\\nâœ… å¤„ç†å®Œæˆ")
    print(f"   æˆåŠŸ: {processed}")
    print(f"   å¤±è´¥: {failed}")


if __name__ == '__main__':
    main()
