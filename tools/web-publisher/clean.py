#!/usr/bin/env python3
"""
GEO OS - æ•°æ®æ¸…æ´—è„šæœ¬
è¿‡æ»¤ä½ä»·å€¼å†…å®¹ï¼Œä¿ç•™ä¼˜è´¨ units

è¿‡æ»¤è§„åˆ™ï¼š
1. é‚®ç®±åˆ—è¡¨ï¼ˆemail å æ¯” > 30%ï¼‰
2. çº¯æ•°æ®è¡¨æ ¼ï¼ˆæ•°å­—/ç¬¦å·å æ¯” > 50%ï¼‰
3. è¿‡çŸ­å†…å®¹ï¼ˆ< 100 å­—ç¬¦ï¼‰
4. è¿‡é•¿é‡å¤å†…å®¹ï¼ˆ> 1000 å­—ç¬¦ä¸”é‡å¤åº¦é«˜ï¼‰
5. æ— æ„ä¹‰å†…å®¹ï¼ˆä¹±ç ã€å ä½ç¬¦ç­‰ï¼‰

ç”¨æ³•ï¼š
    python clean.py --input /path/to/geo_units.json --output /path/to/cleaned_units.json
"""

import json
import re
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from collections import Counter


def is_email_list(content: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºé‚®ç®±åˆ—è¡¨"""
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(email_pattern, content)

    # å¦‚æœé‚®ç®±æ•°é‡ > 10 æˆ–é‚®ç®±å æ¯” > 30%
    if len(emails) > 10:
        return True

    email_chars = sum(len(e) for e in emails)
    if len(content) > 0 and email_chars / len(content) > 0.3:
        return True

    return False


def is_data_table(content: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºçº¯æ•°æ®è¡¨æ ¼"""
    # ç»Ÿè®¡æ•°å­—ã€ç¬¦å·çš„å æ¯”
    digits_symbols = sum(1 for c in content if c.isdigit() or c in '.,;:|()[]{}\\/-_=+*&^%$#@!~`')

    if len(content) > 0 and digits_symbols / len(content) > 0.5:
        return True

    return False


def is_too_short(content: str, min_length: int = 100) -> bool:
    """åˆ¤æ–­å†…å®¹æ˜¯å¦è¿‡çŸ­"""
    # å»é™¤ç©ºç™½åè®¡ç®—é•¿åº¦
    clean_content = content.strip()
    return len(clean_content) < min_length


def is_too_long(content: str, max_length: int = 1000) -> bool:
    """åˆ¤æ–­å†…å®¹æ˜¯å¦è¿‡é•¿"""
    return len(content) > max_length


def is_repetitive(content: str, threshold: float = 0.7) -> bool:
    """åˆ¤æ–­å†…å®¹æ˜¯å¦é«˜åº¦é‡å¤"""
    # æŒ‰è¡Œåˆ†å‰²
    lines = [line.strip() for line in content.split('\n') if line.strip()]

    if len(lines) < 5:
        return False

    # ç»Ÿè®¡é‡å¤è¡Œ
    line_counts = Counter(lines)
    most_common_count = line_counts.most_common(1)[0][1] if line_counts else 0

    # å¦‚æœæŸä¸€è¡Œå‡ºç°æ¬¡æ•° > æ€»è¡Œæ•°çš„ 70%
    if len(lines) > 0 and most_common_count / len(lines) > threshold:
        return True

    return False


def has_meaningful_content(content: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦æœ‰æœ‰æ„ä¹‰çš„å†…å®¹"""
    # ç§»é™¤ç©ºç™½ã€æ ‡ç‚¹
    clean = re.sub(r'[^\w\s]', '', content)
    clean = clean.strip()

    # å¦‚æœåªå‰©ä¸‹å¾ˆå°‘å­—ç¬¦
    if len(clean) < 50:
        return False

    # å¦‚æœæ˜¯ä¹±ç ï¼ˆéä¸­è‹±æ–‡å­—ç¬¦è¿‡å¤šï¼‰
    non_chinese_english = sum(1 for c in clean if not ('\u4e00' <= c <= '\u9fff' or c.isalpha()))
    if len(clean) > 0 and non_chinese_english / len(clean) > 0.5:
        return False

    return True


def calculate_quality_score(unit: Dict) -> int:
    """
    è®¡ç®— unit è´¨é‡åˆ†æ•°ï¼ˆ0-100ï¼‰

    è¯„åˆ†æ ‡å‡†ï¼š
    - æœ‰æ ‡é¢˜ï¼š+30
    - æœ‰åˆ—è¡¨ï¼š+20
    - å­—æ•°åˆç†ï¼ˆ200-800ï¼‰ï¼š+20
    - æœ‰æ„ä¹‰å†…å®¹ï¼š+30
    """
    score = 0
    content = unit.get('content', '')
    metadata = unit.get('metadata', {})

    # 1. æœ‰æ ‡é¢˜
    if metadata.get('headings') and len(metadata['headings']) > 0:
        score += 30

    # 2. æœ‰åˆ—è¡¨
    if metadata.get('bullets') and len(metadata['bullets']) > 0:
        score += 20

    # 3. å­—æ•°åˆç†
    char_count = metadata.get('char_count', len(content))
    if 200 <= char_count <= 800:
        score += 20
    elif 100 <= char_count < 200 or 800 < char_count <= 1000:
        score += 10

    # 4. æœ‰æ„ä¹‰å†…å®¹
    if has_meaningful_content(content):
        score += 30

    return score


def should_filter(unit: Dict) -> tuple[bool, str]:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰è¿™ä¸ª unit

    Returns:
        (æ˜¯å¦è¿‡æ»¤, åŸå› )
    """
    content = unit.get('content', '')

    # 1. é‚®ç®±åˆ—è¡¨
    if is_email_list(content):
        return (True, "é‚®ç®±åˆ—è¡¨")

    # 2. çº¯æ•°æ®è¡¨æ ¼
    if is_data_table(content):
        return (True, "çº¯æ•°æ®è¡¨æ ¼")

    # 3. è¿‡çŸ­å†…å®¹
    if is_too_short(content, min_length=100):
        return (True, "å†…å®¹è¿‡çŸ­")

    # 4. é«˜åº¦é‡å¤
    if is_repetitive(content):
        return (True, "é«˜åº¦é‡å¤")

    # 5. æ— æ„ä¹‰å†…å®¹
    if not has_meaningful_content(content):
        return (True, "æ— æ„ä¹‰å†…å®¹")

    return (False, "")


def clean_units(input_path: Path, output_path: Path, verbose: bool = False):
    """
    æ¸…æ´— units æ•°æ®

    Args:
        input_path: è¾“å…¥ JSON æ–‡ä»¶
        output_path: è¾“å‡º JSON æ–‡ä»¶
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    """
    print(f"ğŸ“¥ åŠ è½½è¾“å…¥ï¼š{input_path}")

    with open(input_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    units = data['units']
    total_units = len(units)

    print(f"ğŸ“Š åŸå§‹æ•°æ®ï¼š{total_units} units")
    print(f"   æ–‡ä»¶å¤§å°ï¼š{input_path.stat().st_size / (1024**2):.1f} MB")
    print()

    # ç»Ÿè®¡
    filtered_units = []
    filter_reasons = Counter()
    quality_scores = []

    print("ğŸ§¹ å¼€å§‹æ¸…æ´—...")

    for i, unit in enumerate(units, 1):
        # åˆ¤æ–­æ˜¯å¦è¿‡æ»¤
        should_remove, reason = should_filter(unit)

        if should_remove:
            filter_reasons[reason] += 1
            if verbose and i <= 20:
                print(f"   [{i}/{total_units}] âŒ è¿‡æ»¤: {unit['id']} - {reason}")
            continue

        # è®¡ç®—è´¨é‡åˆ†æ•°
        score = calculate_quality_score(unit)
        quality_scores.append(score)

        # åªä¿ç•™è´¨é‡åˆ†æ•° >= 30 çš„
        if score >= 30:
            filtered_units.append(unit)
            if verbose and i <= 20:
                print(f"   [{i}/{total_units}] âœ… ä¿ç•™: {unit['id']} - åˆ†æ•°: {score}")
        else:
            filter_reasons["è´¨é‡åˆ†æ•°è¿‡ä½"] += 1

        # è¿›åº¦æ˜¾ç¤º
        if i % 10000 == 0:
            print(f"   [{i}/{total_units}] å·²å¤„ç†...")

    # ç”Ÿæˆæ¸…æ´—åçš„æ•°æ®
    output_data = {
        'version': '0.2.0',
        'cleaned_at': datetime.now().isoformat(),
        'source_file': str(input_path),
        'original_count': total_units,
        'cleaned_count': len(filtered_units),
        'filter_rate': f"{(1 - len(filtered_units)/total_units)*100:.1f}%",
        'units': filtered_units
    }

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜è¾“å‡ºï¼š{output_path}")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    # ç»Ÿè®¡æŠ¥å‘Š
    print(f"\nâœ… æ¸…æ´—å®Œæˆ")
    print(f"   åŸå§‹æ•°é‡ï¼š{total_units}")
    print(f"   ä¿ç•™æ•°é‡ï¼š{len(filtered_units)}")
    print(f"   è¿‡æ»¤æ•°é‡ï¼š{total_units - len(filtered_units)}")
    print(f"   è¿‡æ»¤æ¯”ä¾‹ï¼š{(1 - len(filtered_units)/total_units)*100:.1f}%")
    print(f"   è¾“å‡ºå¤§å°ï¼š{output_path.stat().st_size / (1024**2):.1f} MB")
    print()

    print("ğŸ“Š è¿‡æ»¤åŸå› ç»Ÿè®¡ï¼š")
    for reason, count in filter_reasons.most_common():
        print(f"   {reason}: {count} ({count/total_units*100:.1f}%)")

    if quality_scores:
        print()
        print("ğŸ“Š è´¨é‡åˆ†æ•°åˆ†å¸ƒï¼š")
        print(f"   å¹³å‡åˆ†ï¼š{sum(quality_scores)/len(quality_scores):.1f}")
        print(f"   æœ€é«˜åˆ†ï¼š{max(quality_scores)}")
        print(f"   æœ€ä½åˆ†ï¼š{min(quality_scores)}")

        # åˆ†æ•°æ®µç»Ÿè®¡
        score_ranges = {
            '90-100': sum(1 for s in quality_scores if 90 <= s <= 100),
            '70-89': sum(1 for s in quality_scores if 70 <= s < 90),
            '50-69': sum(1 for s in quality_scores if 50 <= s < 70),
            '30-49': sum(1 for s in quality_scores if 30 <= s < 50),
        }

        for range_name, count in score_ranges.items():
            if count > 0:
                print(f"   {range_name}åˆ†: {count} ({count/len(quality_scores)*100:.1f}%)")


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®æ¸…æ´—è„šæœ¬')
    parser.add_argument('--input', type=str, help='è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, help='è¾“å‡º JSON æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')

    args = parser.parse_args()

    # é»˜è®¤è·¯å¾„
    if not args.input:
        args.input = str(Path.home() / 'data/exports/amazon_local/geo_units_v0.1.json')

    if not args.output:
        args.output = str(Path.home() / 'data/exports/amazon_local/cleaned_units.json')

    input_path = Path(args.input)
    output_path = Path(args.output)

    # æ‰§è¡Œæ¸…æ´—
    clean_units(input_path, output_path, verbose=args.verbose)

    return 0


if __name__ == '__main__':
    exit(main())
