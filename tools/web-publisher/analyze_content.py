#!/usr/bin/env python3
"""
åˆ†æ Markdown å†…å®¹è´¨é‡ï¼Œæ‰¾å‡ºçœŸæ­£æœ‰ä»·å€¼çš„æ–‡ç« 
"""

import re
from pathlib import Path
from typing import Dict, List


def analyze_file(file_path: Path) -> Dict:
    """åˆ†æå•ä¸ªæ–‡ä»¶çš„å†…å®¹è´¨é‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # åˆ†ç¦» frontmatter
        parts = content.split('---', 2)
        if len(parts) >= 3:
            body = parts[2]
        else:
            body = content

        # ç»Ÿè®¡æŒ‡æ ‡
        lines = body.strip().split('\n')
        total_lines = len(lines)

        # ç»Ÿè®¡å®é™…å†…å®¹è¡Œï¼ˆéç©ºè¡Œã€éè¡¨å¤´ã€éåˆ†éš”ç¬¦ï¼‰
        content_lines = 0
        table_header_lines = 0
        table_separator_lines = 0
        empty_lines = 0

        for line in lines:
            stripped = line.strip()
            if not stripped:
                empty_lines += 1
            elif re.match(r'^\|[\s\-:]+\|', stripped):
                # è¡¨æ ¼åˆ†éš”ç¬¦
                table_separator_lines += 1
            elif '|' in stripped and not any(word in stripped for word in ['ASIN', 'SKU', 'å•†å“åç§°', 'æ—¥æœŸ', 'å¹¿å‘Š', 'é”€å”®', 'è®¢å•']):
                # å¯èƒ½æ˜¯æ•°æ®è¡Œ
                content_lines += 1
            elif '|' in stripped:
                # è¡¨å¤´è¡Œ
                table_header_lines += 1
            elif len(stripped) > 10:
                # æ™®é€šæ–‡æœ¬è¡Œï¼ˆè‡³å°‘ 10 ä¸ªå­—ç¬¦ï¼‰
                content_lines += 1

        # åˆ¤æ–­å†…å®¹è´¨é‡
        has_real_content = content_lines > 5  # è‡³å°‘ 5 è¡Œå®é™…å†…å®¹
        content_ratio = content_lines / total_lines if total_lines > 0 else 0

        return {
            'path': str(file_path),
            'name': file_path.name,
            'total_lines': total_lines,
            'content_lines': content_lines,
            'table_headers': table_header_lines,
            'table_separators': table_separator_lines,
            'empty_lines': empty_lines,
            'content_ratio': content_ratio,
            'has_real_content': has_real_content,
        }

    except Exception as e:
        print(f"   âŒ {file_path.name}: {e}")
        return None


def main():
    posts_dir = Path.home() / 'github/liye_os/websites/amazon-optimization/src/content/posts'

    print(f"ğŸ“Š åˆ†æå†…å®¹è´¨é‡...\\n   ç›®å½•: {posts_dir}\\n")

    md_files = sorted(posts_dir.glob('*.md'))
    results = []

    for file_path in md_files:
        result = analyze_file(file_path)
        if result:
            results.append(result)

    # åˆ†ç±»
    good_files = [r for r in results if r['has_real_content']]
    empty_files = [r for r in results if not r['has_real_content']]

    print(f"\\nğŸ“ˆ ç»Ÿè®¡ç»“æœï¼š")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(results)}")
    print(f"   æœ‰å®é™…å†…å®¹: {len(good_files)} ({len(good_files)/len(results)*100:.1f}%)")
    print(f"   å†…å®¹ä¸ºç©º: {len(empty_files)} ({len(empty_files)/len(results)*100:.1f}%)")

    print(f"\\nâœ… æœ‰ä»·å€¼çš„æ–‡ä»¶ï¼ˆå‰ 20 ä¸ªï¼‰ï¼š")
    good_sorted = sorted(good_files, key=lambda x: x['content_lines'], reverse=True)
    for i, r in enumerate(good_sorted[:20], 1):
        print(f"   {i}. {r['name']} - {r['content_lines']} è¡Œå†…å®¹ ({r['content_ratio']*100:.1f}%)")

    print(f"\\nâŒ ç©ºæ–‡ä»¶ç¤ºä¾‹ï¼ˆå‰ 10 ä¸ªï¼‰ï¼š")
    for i, r in enumerate(empty_files[:10], 1):
        print(f"   {i}. {r['name']} - ä»… {r['content_lines']} è¡Œå†…å®¹")

    # ä¿å­˜æœ‰ä»·å€¼çš„æ–‡ä»¶åˆ—è¡¨
    good_files_list = Path.home() / 'github/liye_os/tools/web-publisher/good_files.txt'
    with open(good_files_list, 'w', encoding='utf-8') as f:
        for r in good_sorted:
            f.write(f"{r['name']}\\n")

    print(f"\\nğŸ’¾ å·²ä¿å­˜æœ‰ä»·å€¼çš„æ–‡ä»¶åˆ—è¡¨åˆ°: {good_files_list}")


if __name__ == '__main__':
    main()
