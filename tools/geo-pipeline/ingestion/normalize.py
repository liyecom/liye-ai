"""
GEO OS - Normalize Module
æ ‡å‡†åŒ–æ¨¡å—ï¼šå°†å„ç±»æ–‡æ¡£è½¬ä¸ºMarkdown

èŒè´£ï¼š
- ä½¿ç”¨MarkItDownè½¬æ¢å¤šç§æ–‡ä»¶æ ¼å¼
- å¤„ç† PDF, DOCX, PPTX, XLSX ç­‰
- è¾“å‡ºæ ‡å‡†åŒ–çš„Markdown

æ”¯æŒæ ¼å¼ï¼š
- PDF (.pdf)
- Word (.docx)
- PowerPoint (.pptx)
- Excel (.xlsx)
- HTML (.html)
- Text (.txt, .md)
"""

from pathlib import Path


def convert_to_markdown(file_path):
    """
    å°†æ–‡ä»¶è½¬æ¢ä¸ºMarkdown

    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼ˆPathå¯¹è±¡æˆ–å­—ç¬¦ä¸²ï¼‰

    Returns:
        str: Markdownå†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    file_path = Path(file_path)

    # è·å–æ–‡ä»¶æ‰©å±•å
    ext = file_path.suffix.lower()

    # æ”¯æŒçš„æ ¼å¼
    supported_formats = ['.pdf', '.docx', '.pptx', '.xlsx', '.html', '.htm']
    text_formats = ['.txt', '.md', '.markdown']

    try:
        # å¦‚æœæ˜¯çº¯æ–‡æœ¬æ ¼å¼ï¼Œç›´æ¥è¯»å–
        if ext in text_formats:
            return file_path.read_text(encoding='utf-8', errors='ignore')

        # å¦‚æœæ˜¯æ”¯æŒçš„æ ¼å¼ï¼Œä½¿ç”¨MarkItDown
        if ext in supported_formats:
            try:
                from markitdown import MarkItDown
                md = MarkItDown()
                result = md.convert(str(file_path))

                if result and result.text_content:
                    return result.text_content
                else:
                    return None
            except ImportError:
                print(f"   âš ï¸  MarkItDown not installed, skipping {file_path.name}")
                return None

        # ä¸æ”¯æŒçš„æ ¼å¼
        return None

    except Exception as e:
        print(f"   âš ï¸  Error converting {file_path.name}: {e}")
        return None


def get_supported_files(source_dir):
    """
    è·å–ç›®å½•ä¸­æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶

    Args:
        source_dir: æºç›®å½•è·¯å¾„

    Returns:
        list: æ”¯æŒçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    supported_exts = {'.pdf', '.docx', '.pptx', '.xlsx', '.html', '.htm', '.txt', '.md', '.markdown'}

    all_files = []
    for file_path in Path(source_dir).rglob('*'):
        if file_path.is_file() and file_path.suffix.lower() in supported_exts:
            all_files.append(file_path)

    return all_files


def normalize(config, dry_run=False):
    """
    å°†å„ç±»æ–‡æ¡£è½¬ä¸ºMarkdown

    Args:
        config: é…ç½®å­—å…¸
        dry_run: æ˜¯å¦å¹²è¿è¡Œ

    Returns:
        è½¬æ¢ç»Ÿè®¡ä¿¡æ¯
    """
    print("ğŸ“‹ Normalize: å„ç±»æ–‡æ¡£ â†’ Markdown")

    source_dir = config['paths']['source']
    output_dir = config['paths']['processed'] / 'raw_md'

    # è·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶
    files_to_process = get_supported_files(source_dir)

    print(f"   Found {len(files_to_process)} files")

    if len(files_to_process) == 0:
        print("   âš ï¸  No files to process")
        return {"files_found": 0, "files_processed": 0, "files_skipped": 0, "files_failed": 0}

    if dry_run:
        print("   [DRY RUN] Would convert files to Markdown")
        print(f"   Output directory: {output_dir}")
        # æ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        for f in files_to_process[:5]:
            rel_path = f.relative_to(source_dir)
            print(f"     - {rel_path}")
        if len(files_to_process) > 5:
            print(f"     ... and {len(files_to_process) - 5} more files")
        return {
            "files_found": len(files_to_process),
            "files_processed": 0,
            "files_skipped": 0,
            "files_failed": 0
        }

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç»Ÿè®¡
    converted_count = 0
    skipped_count = 0
    failed_count = 0

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, file_path in enumerate(files_to_process, 1):
        try:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = file_path.relative_to(source_dir)

            # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¿æŒç›®å½•ç»“æ„ï¼‰
            output_file = output_dir / rel_path.parent / f"{file_path.stem}.md"

            # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
            if output_file.exists():
                skipped_count += 1
                if i <= 10 or i % 100 == 0:  # åªæ˜¾ç¤ºå‰10ä¸ªå’Œæ¯100ä¸ª
                    print(f"   [{i}/{len(files_to_process)}] Skipped (exists): {rel_path}")
                continue

            # è½¬æ¢
            md_content = convert_to_markdown(file_path)

            if md_content is None:
                failed_count += 1
                if i <= 10 or i % 100 == 0:
                    print(f"   [{i}/{len(files_to_process)}] Failed: {rel_path}")
                continue

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_file.parent.mkdir(parents=True, exist_ok=True)

            # å†™å…¥
            output_file.write_text(md_content, encoding='utf-8')
            converted_count += 1

            if i <= 10 or i % 100 == 0:
                print(f"   [{i}/{len(files_to_process)}] âœ… {rel_path} â†’ {output_file.name}")

        except Exception as e:
            failed_count += 1
            if i <= 10 or i % 100 == 0:
                print(f"   [{i}/{len(files_to_process)}] âŒ {file_path.name}: {e}")

    # æ€»ç»“
    print(f"\n   âœ… Conversion complete:")
    print(f"      Files found: {len(files_to_process)}")
    print(f"      Converted: {converted_count}")
    print(f"      Skipped: {skipped_count}")
    print(f"      Failed: {failed_count}")

    return {
        "files_found": len(files_to_process),
        "files_processed": converted_count,
        "files_skipped": skipped_count,
        "files_failed": failed_count
    }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from pathlib import Path

    print("Testing normalize module...")
    test_config = {
        'paths': {
            'source': Path.home() / 'data/archives/shengcai',
            'processed': Path.home() / 'data/processed/shengcai'
        }
    }
    normalize(test_config, dry_run=True)
