"""
Geo Pipeline - Chunk Module
åˆ†å—æ¨¡å—ï¼šå°†é•¿æ–‡æ¡£åˆ†å‰²ä¸ºå›ºå®šå¤§å°çš„chunks

èŒè´£ï¼š
- æŒ‰å›ºå®šå¤§å°åˆ†å—ï¼ˆå¸¦é‡å ï¼‰
- ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
- è¾“å‡ºchunk JSON
"""

import json
from pathlib import Path


def chunk_text(text, chunk_size=600, overlap=100):
    """
    ç®€å•æ»‘åŠ¨çª—å£åˆ†å—

    Args:
        text: æ–‡æœ¬å†…å®¹
        chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
        overlap: é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰

    Returns:
        chunksåˆ—è¡¨
    """
    chunks = []
    start = 0
    text_length = len(text)

    # å¦‚æœæ–‡æœ¬ä¸ºç©ºæˆ–å¾ˆçŸ­ï¼Œè¿”å›å•ä¸ªchunk
    if text_length == 0:
        return []

    if text_length <= chunk_size:
        return [{
            'start': 0,
            'end': text_length,
            'content': text.strip(),
            'char_count': text_length
        }]

    # æ»‘åŠ¨çª—å£åˆ†å—
    while start < text_length:
        end = min(start + chunk_size, text_length)
        chunk_content = text[start:end]

        # åªä¿å­˜éç©ºchunk
        if chunk_content.strip():
            chunks.append({
                'start': start,
                'end': end,
                'content': chunk_content,
                'char_count': len(chunk_content)
            })

        # ç§»åŠ¨çª—å£ï¼ˆchunk_size - overlapï¼‰
        start += (chunk_size - overlap)

        # å¦‚æœä¸‹ä¸€ä¸ªèµ·ç‚¹å·²ç»è¶…è¿‡æ–‡æœ¬é•¿åº¦ï¼Œåœæ­¢
        if start >= text_length:
            break

    return chunks


def chunk_documents(config, dry_run=False):
    """
    å°†Markdownæ–‡æ¡£åˆ†å—

    Args:
        config: é…ç½®å­—å…¸
        dry_run: æ˜¯å¦å¹²è¿è¡Œ

    Returns:
        åˆ†å—ç»Ÿè®¡ä¿¡æ¯
    """
    print("ğŸ“‹ Chunk: Markdown â†’ å›ºå®šå¤§å°chunks")

    input_dir = config['paths']['processed'] / 'raw_md'
    output_dir = config['paths']['processed'] / 'chunks'

    # è·å–æ‰€æœ‰Markdownæ–‡ä»¶
    md_files = list(input_dir.rglob('*.md'))
    print(f"   Found {len(md_files)} markdown files")

    if len(md_files) == 0:
        print("   âš ï¸  No markdown files to process")
        return {"files_found": 0, "files_processed": 0, "chunks_created": 0}

    if dry_run:
        print("   [DRY RUN] Would chunk documents")
        print(f"   Output directory: {output_dir}")
        print(f"   Chunk size: {config['processing']['chunk_size']}")
        print(f"   Overlap: {config['processing']['chunk_overlap']}")
        # æ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶ä½œä¸ºç¤ºä¾‹
        for f in md_files[:5]:
            rel_path = f.relative_to(input_dir)
            print(f"     - {rel_path}")
        if len(md_files) > 5:
            print(f"     ... and {len(md_files) - 5} more files")
        return {
            "files_found": len(md_files),
            "files_processed": 0,
            "chunks_created": 0
        }

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç»Ÿè®¡
    total_chunks = 0
    processed_count = 0
    skipped_count = 0
    failed_count = 0

    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for i, md_file in enumerate(md_files, 1):
        try:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = md_file.relative_to(input_dir)

            # è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¿æŒç›®å½•ç»“æ„ï¼‰
            output_file = output_dir / rel_path.parent / f"{md_file.stem}_chunks.json"

            # å¦‚æœå·²å­˜åœ¨ï¼Œè·³è¿‡
            if output_file.exists():
                skipped_count += 1
                if i <= 10 or i % 100 == 0:  # åªæ˜¾ç¤ºå‰10ä¸ªå’Œæ¯100ä¸ª
                    print(f"   [{i}/{len(md_files)}] Skipped (exists): {rel_path}")
                continue

            # è¯»å–å†…å®¹
            content = md_file.read_text(encoding='utf-8', errors='ignore')

            # åˆ†å—
            chunks = chunk_text(
                content,
                chunk_size=config['processing']['chunk_size'],
                overlap=config['processing']['chunk_overlap']
            )

            if len(chunks) == 0:
                skipped_count += 1
                if i <= 10 or i % 100 == 0:
                    print(f"   [{i}/{len(md_files)}] Skipped (empty): {rel_path}")
                continue

            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_file.parent.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜chunks JSON
            chunk_data = {
                'source_file': str(md_file),
                'chunk_count': len(chunks),
                'total_chars': len(content),
                'chunks': chunks
            }

            output_file.write_text(
                json.dumps(chunk_data, indent=2, ensure_ascii=False),
                encoding='utf-8'
            )

            total_chunks += len(chunks)
            processed_count += 1

            if i <= 10 or i % 100 == 0:
                print(f"   [{i}/{len(md_files)}] âœ… {rel_path} â†’ {len(chunks)} chunks")

        except Exception as e:
            failed_count += 1
            if i <= 10 or i % 100 == 0:
                print(f"   [{i}/{len(md_files)}] âŒ {md_file.name}: {e}")

    # æ€»ç»“
    print(f"\n   âœ… Chunking complete:")
    print(f"      Files found: {len(md_files)}")
    print(f"      Processed: {processed_count}")
    print(f"      Skipped: {skipped_count}")
    print(f"      Failed: {failed_count}")
    print(f"      Total chunks: {total_chunks}")

    return {
        "files_found": len(md_files),
        "files_processed": processed_count,
        "files_skipped": skipped_count,
        "files_failed": failed_count,
        "chunks_created": total_chunks
    }


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from pathlib import Path

    print("Testing chunk module...")

    # æµ‹è¯•1: chunk_textå‡½æ•°
    print("\n1. Testing chunk_text function:")
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚" * 100  # çº¦800å­—ç¬¦
    chunks = chunk_text(test_text, chunk_size=200, overlap=50)
    print(f"   Text length: {len(test_text)}")
    print(f"   Chunks created: {len(chunks)}")
    if chunks:
        print(f"   First chunk: {chunks[0]['start']}-{chunks[0]['end']} ({chunks[0]['char_count']} chars)")
        print(f"   Last chunk: {chunks[-1]['start']}-{chunks[-1]['end']} ({chunks[-1]['char_count']} chars)")

    # æµ‹è¯•2: chunk_documentså‡½æ•°ï¼ˆdry runï¼‰
    print("\n2. Testing chunk_documents function (dry run):")
    test_config = {
        'paths': {
            'processed': Path.home() / 'data/processed/shengcai'
        },
        'processing': {
            'chunk_size': 600,
            'chunk_overlap': 100
        }
    }
    chunk_documents(test_config, dry_run=True)
