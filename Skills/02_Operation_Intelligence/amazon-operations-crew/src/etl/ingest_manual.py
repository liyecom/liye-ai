import duckdb
import pandas as pd
import os
import glob
from pathlib import Path
from datetime import datetime

# Database Path
DB_PATH = "data/growth_os.duckdb"
UPLOADS_DIR = "uploads"

def init_db(con):
    """Initialize tables for manual data."""
    # 1. Traffic Table (From Business Report)
    con.execute("DROP TABLE IF EXISTS factor_traffic_daily")
    con.execute("""
        CREATE TABLE IF NOT EXISTS factor_traffic_daily (
            parent_asin VARCHAR,
            child_asin VARCHAR,
            title VARCHAR,
            sessions INTEGER,
            sessions_b2b INTEGER,
            session_percentage VARCHAR,
            page_views INTEGER,
            buy_box_percentage VARCHAR,
            units_ordered INTEGER,
            unit_session_percentage VARCHAR, -- Conversion Rate
            ordered_product_sales VARCHAR,
            total_order_items INTEGER,
            report_date DATE,
            report_type VARCHAR
        )
    """)
    
    # 2. Search Term Table (From Advertising Report)
    con.execute("DROP TABLE IF EXISTS factor_search_term_performance")
    con.execute("""
        CREATE TABLE IF NOT EXISTS factor_search_term_performance (
            campaign_name VARCHAR,
            ad_group_name VARCHAR,
            targeting VARCHAR,
            match_type VARCHAR,
            customer_search_term VARCHAR,
            impressions INTEGER,
            clicks INTEGER,
            ctr DOUBLE,
            spend DOUBLE,
            cpc DOUBLE,
            orders INTEGER,
            sales DOUBLE,
            acos DOUBLE,
            roas DOUBLE,
            report_date DATE
        )
    """)

    # 3. Competitor Keywords (From SellersSprite Reverse ASIN)
    con.execute("DROP TABLE IF EXISTS factor_competitor_keywords")
    con.execute("""
        CREATE TABLE IF NOT EXISTS factor_competitor_keywords (
            asin VARCHAR,
            keyword VARCHAR,
            search_volume INTEGER,
            sales_volume INTEGER,
            organic_rank INTEGER,
            sponsored_rank INTEGER,
            traffic_share VARCHAR,
            market_analysis VARCHAR,
            ingestion_date DATE
        )
    """)
    print("âœ… Database schema initialized.")

def clean_money(val):
    if isinstance(val, str):
        return float(val.replace('US$', '').replace('$', '').replace(',', '').strip() or 0)
    return float(val or 0)

def clean_int(val):
    if val is None: return 0
    # Handle NaN (float('nan') != float('nan'))
    if isinstance(val, float) and val != val: return 0
    
    if isinstance(val, (int, float)): return int(val)
    
    val_str = str(val).strip()
    if not val_str or val_str in ['-', 'N/A', 'nan', 'å‰3é¡µæ— æ’å', 'å‰3é¡µæ— å¹¿å‘Š', 'å‰3é ç„¡æ’å', 'å‰3é ç„¡å»£å‘Š']: return 0
    # Common cleaning
    val_str = val_str.replace(',', '').replace('>', '').replace('<', '')
    try:
        return int(float(val_str))
    except:
        return 0

def ingest_business_report(con):
    """Ingest Amazon Business Reports (CSV)"""
    files = glob.glob(os.path.join(UPLOADS_DIR, "BusinessReport*.csv"))
    for file in files:
        print(f"--> Processing Business Report: {file}")
        try:
            # Amazon reports often have a header description in the first few lines or just start with headers
            # We try reading normally first
            df = pd.read_csv(file)
            
            # Sanitizing column names
            df.columns = [c.strip() for c in df.columns]
            
            # Map Chinese/English Headers
            # Key mappings based on your 'head' output
            # (çˆ¶) ASIN -> parent_asin
            # (å­) ASIN -> child_asin
            # æ¨™é¡Œ -> title
            # å·¥ä½œéšæ®µ - ç¸½è¨ˆ -> sessions
            # é é¢ç€è¦½æ¬¡æ•¸ - ç¸½è¨ˆ -> page_views
            # å·²è¨‚è³¼å–®ä½æ•¸é‡ -> units_ordered (Units Ordered)
            # å•†å“å·¥ä½œéšæ®µç™¾åˆ†æ¯” -> unit_session_percentage (Unit Session Percentage / CVR)
            # è¨‚è³¼ç”¢å“éŠ·å”®é¡ -> ordered_product_sales
            
            for _, row in df.iterrows():
                parent = row.get('(çˆ¶) ASIN') or row.get('Parent ASIN')
                child = row.get('(å­) ASIN') or row.get('Child ASIN')
                if not child: continue

                con.execute(f"""
                    INSERT INTO factor_traffic_daily VALUES (
                        ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_DATE, ?
                    )
                """, (
                    parent,
                    child,
                    row.get('æ¨™é¡Œ', '') or row.get('Title', ''),
                    clean_int(row.get('å·¥ä½œéšæ®µ - ç¸½è¨ˆ') or row.get('Sessions - Total')),
                    clean_int(row.get('å·¥ä½œéšæ®µæ•¸ â€“ ç¸½è¨ˆ â€“ B2B') or row.get('Sessions - Total - B2B')),
                    row.get('å·¥ä½œéšæ®µç™¾åˆ†æ¯” â€“ ç¸½è¨ˆ', ''),
                    clean_int(row.get('é é¢ç€è¦½æ¬¡æ•¸ - ç¸½è¨ˆ') or row.get('Page Views - Total')),
                    row.get('ç²¾é¸å„ªæƒ  (å ±åƒ¹é¡¯ç¤º) ç™¾åˆ†æ¯”', ''),
                    clean_int(row.get('å·²è¨‚è³¼å–®ä½æ•¸é‡') or row.get('Units Ordered')),
                    row.get('å•†å“å·¥ä½œéšæ®µç™¾åˆ†æ¯”') or row.get('Unit Session Percentage'),
                    row.get('è¨‚è³¼ç”¢å“éŠ·å”®é¡') or row.get('Ordered Product Sales'),
                    clean_int(row.get('è¨‚å–®å•†å“ç¸½æ•¸') or row.get('Total Order Items')),
                    'YTD' if 'å¹´åº¦' in file else '30Day'
                ))
            print(f"âœ… Ingested {len(df)} rows from {file}")
            
        except Exception as e:
            print(f"âŒ Error reading {file}: {e}")

def ingest_search_term_report(con):
    """Ingest Flywheel/Amazon Search Term Reports (XLSX/CSV)"""
    files = glob.glob(os.path.join(UPLOADS_DIR, "*å•†å“æ¨å»£*æœå°‹å­—è©*.xlsx")) + \
            glob.glob(os.path.join(UPLOADS_DIR, "*SearchTerm*.xlsx")) + \
            glob.glob(os.path.join(UPLOADS_DIR, "*ç³»ç»Ÿ-TIMO*.xlsx")) # Catch Flywheel/Saihu
    
    unique_files = list(set(files))
    
    for file in files:
        print(f"--> Processing Search Term Report: {file}")
        try:
            df = pd.read_excel(file)
            df.columns = [c.strip() for c in df.columns]
            
            count = 0
            for _, row in df.iterrows():
                # Flexible column fetch
                term = row.get('Customer Search Term') or row.get('å®¢æˆ¶æœå°‹è©') or row.get('å…³é”®è¯') or row.get('æœç´¢è¯') or row.get('å®¢æˆ·æœç´¢è¯') or row.get('å®¢æˆ¶æœå°‹å­—è©')
                if not term: continue
                
                con.execute("""
                    INSERT INTO factor_search_term_performance (
                        campaign_name, ad_group_name, customer_search_term, impressions, clicks, spend, sales, report_date
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_DATE)
                """, (
                    row.get('Campaign Name') or row.get('å¹¿å‘Šæ´»åŠ¨åç§°') or row.get('å»£å‘Šæ´»å‹•åç¨±'),
                    row.get('Ad Group Name') or row.get('å¹¿å‘Šç»„åç§°') or row.get('å»£å‘Šç¾¤çµ„åç¨±'),
                    term,
                    clean_int(row.get('Impressions') or row.get('å±•ç¤ºæ¬¡æ•°') or row.get('æ›å…‰æ•¸') or row.get('å»£å‘Šæ›å…‰')),
                    clean_int(row.get('Clicks') or row.get('ç‚¹å‡»é‡') or row.get('é»æ“Šæ¬¡æ•¸') or row.get('é»æ“Š')),
                    clean_money(row.get('Spend') or row.get('èŠ±è´¹') or row.get('èŠ±è²»') or row.get('æ”¯å‡º')),
                    clean_money(row.get('Sales') or row.get('7 Day Total Sales') or row.get('7å¤©æ€»é”€å”®é¢') or row.get('7 å¤©ç¸½éŠ·å”®é¡') or row.get('7 å¤©æ€»é”€å”®é¢') or row.get('7 å¤©ç¸½éŠ·å”®é¡ '))
                ))
                count += 1
            print(f"âœ… Ingested {count} search terms from {file}")
            
        except Exception as e:
            print(f"âŒ Error reading {file}: {e}")

def ingest_sellersprite_reverse(con):
    """Ingest SellersSprite Reverse ASIN Report"""
    files = glob.glob(os.path.join(UPLOADS_DIR, "*ReverseASIN*.xlsx"))
    
    for file in files:
        print(f"--> Processing SellersSprite: {file}")
        try:
            df = pd.read_excel(file)
            df.columns = [c.strip() for c in df.columns]
            
            # Infer ASIN from filename
            current_asin = "B08SWLTTSW" # Default/Fallback
            if "B0D1FN69FC" in file: current_asin = "B0D1FN69FC"
            elif "B0FJF79MMS" in file: current_asin = "B0FJF79MMS"
            
            count = 0
            for _, row in df.iterrows():
                keyword = row.get('Keyword') or row.get('å…³é”®è¯')
                if not keyword: continue
                
                con.execute("""
                    INSERT INTO factor_competitor_keywords (
                        asin, keyword, search_volume, sales_volume, organic_rank, sponsored_rank, traffic_share, market_analysis, ingestion_date
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, CURRENT_DATE)
                """, (
                    current_asin,
                    keyword,
                    clean_int(row.get('Search Volume') or row.get('æœˆæœç´¢é‡')),
                    clean_int(row.get('Sales Volume') or row.get('æœˆè´­ä¹°é‡')), # Assuming this field exists, else 0
                    clean_int(row.get('Organic Rank') or row.get('è‡ªç„¶æ’å')),
                    clean_int(row.get('Sponsored Rank') or row.get('å¹¿å‘Šæ’å')),
                    # Traffic Share might need string cleaning if it has %
                    str(row.get('Traffic Share') or row.get('æµé‡å æ¯”')),
                    file 
                ))
                count += 1
            print(f"âœ… Ingested {count} keywords from {file}")
            
        except Exception as e:
            print(f"âŒ Error reading {file}: {e}")

def main():
    con = duckdb.connect(DB_PATH)
    init_db(con)
    ingest_business_report(con)
    ingest_search_term_report(con)
    ingest_sellersprite_reverse(con)
    con.close()
    print("ğŸš€ All Data Ingestion Complete!")

if __name__ == "__main__":
    main()
