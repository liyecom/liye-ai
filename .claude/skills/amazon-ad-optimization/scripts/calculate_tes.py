#!/usr/bin/env python3
"""
TIMO ç¾å›½ç«™å…³é”®è¯ç»´åº¦æ·±åº¦åˆ†æ
æ•´åˆ: å–å®¶ç²¾çµP2åæŸ¥ + é£è½®3ç»´åº¦ï¼ˆå¹¿å‘Šæ´»åŠ¨/æŠ•æ”¾/æœç´¢è¯ï¼‰
"""

import pandas as pd
import glob
from pathlib import Path
from datetime import datetime

# æ•°æ®è·¯å¾„
UPLOADS_DIR = Path("/Users/liye/Documents/amazon-runtime/uploads/Timo-US")
REPORTS_DIR = Path("/Users/liye/Documents/amazon-runtime/reports/markdown")

# 5ä¸ªASINåˆ—è¡¨
ASINS = [
    "B08SVXGTRT",
    "B08SWLTTSW",
    "B09PQJ8SW8",
    "B08SW4Z85K",  # æ— å¹¿å‘Šæ•°æ®
    "B09PQPYDBM"
]

def load_sellersprite_data(asin):
    """åŠ è½½å–å®¶ç²¾çµP2åæŸ¥æ•°æ®"""
    pattern = f"ReverseASIN-US-{asin}-*.xlsx"
    files = list(UPLOADS_DIR.glob(pattern))

    if not files:
        print(f"âš ï¸ æœªæ‰¾åˆ°{asin}çš„å–å®¶ç²¾çµæ•°æ®")
        return None

    file = files[0]
    print(f"  âœ“ åŠ è½½å–å®¶ç²¾çµ: {file.name}")

    try:
        df = pd.read_excel(file)
        # æ¸…ç†åˆ—å
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"  âŒ è¯»å–å¤±è´¥: {e}")
        return None

def load_flywheel_campaign_data(asin):
    """åŠ è½½é£è½®-å¹¿å‘Šæ´»åŠ¨é‡æ„æ•°æ®"""
    pattern = f"*äº§å“{asin}-å¹¿å‘Šæ´»åŠ¨é‡æ„-*.xlsx"
    files = list(UPLOADS_DIR.glob(pattern))

    if not files:
        print(f"  âš ï¸ æœªæ‰¾åˆ°{asin}çš„é£è½®å¹¿å‘Šæ´»åŠ¨æ•°æ®")
        return None

    file = files[0]
    print(f"  âœ“ åŠ è½½é£è½®-å¹¿å‘Šæ´»åŠ¨: {file.name}")

    try:
        df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"  âŒ è¯»å–å¤±è´¥: {e}")
        return None

def load_flywheel_targeting_data(asin):
    """åŠ è½½é£è½®-æŠ•æ”¾é‡æ„æ•°æ®"""
    pattern = f"*äº§å“{asin}-æŠ•æ”¾é‡æ„-*.xlsx"
    files = list(UPLOADS_DIR.glob(pattern))

    if not files:
        print(f"  âš ï¸ æœªæ‰¾åˆ°{asin}çš„é£è½®æŠ•æ”¾æ•°æ®")
        return None

    file = files[0]
    print(f"  âœ“ åŠ è½½é£è½®-æŠ•æ”¾: {file.name}")

    try:
        df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"  âŒ è¯»å–å¤±è´¥: {e}")
        return None

def load_flywheel_searchterm_data(asin):
    """åŠ è½½é£è½®-æœç´¢è¯é‡æ„æ•°æ®"""
    pattern = f"*äº§å“{asin}-æœç´¢è¯é‡æ„-*.xlsx"
    files = list(UPLOADS_DIR.glob(pattern))

    if not files:
        print(f"  âš ï¸ æœªæ‰¾åˆ°{asin}çš„é£è½®æœç´¢è¯æ•°æ®")
        return None

    file = files[0]
    print(f"  âœ“ åŠ è½½é£è½®-æœç´¢è¯: {file.name}")

    try:
        df = pd.read_excel(file)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"  âŒ è¯»å–å¤±è´¥: {e}")
        return None

def calculate_tes(row):
    """
    è®¡ç®—TES (Traffic Efficiency Score)
    TES = (æœˆæœç´¢é‡ Ã— è´­ä¹°ç‡) / (æ ‡é¢˜å¯†åº¦ + 1)
    """
    try:
        search_volume = float(row.get('æœˆæœç´¢é‡', 0) or 0)
        purchase_rate = float(row.get('è´­ä¹°ç‡', 0) or 0)
        title_density = float(row.get('æ ‡é¢˜å¯†åº¦', 0) or 0)

        tes = (search_volume * purchase_rate) / (title_density + 1)
        return round(tes, 2)
    except:
        return 0

def classify_keyword_by_tes(tes):
    """æ ¹æ®TESåˆ†ç±»å…³é”®è¯"""
    if tes > 100:
        return "ğŸ† WINNER"
    elif tes >= 10:
        return "ğŸ’ POTENTIAL"
    else:
        return "ğŸ“Š BROAD"

def analyze_asin(asin):
    """åˆ†æå•ä¸ªASINçš„å…³é”®è¯ç»´åº¦"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š åˆ†æASIN: {asin}")
    print(f"{'='*80}")

    # åŠ è½½å–å®¶ç²¾çµæ•°æ®
    ss_data = load_sellersprite_data(asin)

    # åŠ è½½é£è½®3ç»´åº¦æ•°æ®
    fw_campaign = load_flywheel_campaign_data(asin)
    fw_targeting = load_flywheel_targeting_data(asin)
    fw_searchterm = load_flywheel_searchterm_data(asin)

    results = {
        'asin': asin,
        'sellersprite': ss_data,
        'flywheel_campaign': fw_campaign,
        'flywheel_targeting': fw_targeting,
        'flywheel_searchterm': fw_searchterm
    }

    # åˆ†æå–å®¶ç²¾çµå…³é”®è¯
    if ss_data is not None and not ss_data.empty:
        print(f"\nğŸ“ˆ å–å®¶ç²¾çµå…³é”®è¯åˆ†æ:")
        print(f"  æ€»å…³é”®è¯æ•°: {len(ss_data)}")

        # è®¡ç®—TES
        ss_data['TES'] = ss_data.apply(calculate_tes, axis=1)
        ss_data['åˆ†ç±»'] = ss_data['TES'].apply(classify_keyword_by_tes)

        # ç»Ÿè®¡åˆ†ç±»
        category_counts = ss_data['åˆ†ç±»'].value_counts()
        print(f"\n  å…³é”®è¯åˆ†ç±»:")
        for category, count in category_counts.items():
            print(f"    {category}: {count}ä¸ª")

        # Topå…³é”®è¯
        top_keywords = ss_data.nlargest(10, 'TES')[['å…³é”®è¯', 'TES', 'æœˆæœç´¢é‡', 'è´­ä¹°ç‡', 'æ ‡é¢˜å¯†åº¦', 'åˆ†ç±»']]
        print(f"\n  Top 10å…³é”®è¯ï¼ˆæŒ‰TESæ’åºï¼‰:")
        print(top_keywords.to_string(index=False))

        # æµé‡ç¼ºå£è¯ï¼ˆé«˜TESä½†ä½æ ‡é¢˜å¯†åº¦ï¼‰
        gap_keywords = ss_data[(ss_data['TES'] > 50) & (ss_data['æ ‡é¢˜å¯†åº¦'] < 30)]
        if not gap_keywords.empty:
            print(f"\n  ğŸ¯ æµé‡ç¼ºå£è¯ï¼ˆTES>50 ä¸”æ ‡é¢˜å¯†åº¦<30%ï¼‰: {len(gap_keywords)}ä¸ª")
            print(gap_keywords[['å…³é”®è¯', 'TES', 'æœˆæœç´¢é‡', 'æ ‡é¢˜å¯†åº¦']].head(10).to_string(index=False))

        results['top_keywords'] = top_keywords
        results['gap_keywords'] = gap_keywords

    # åˆ†æé£è½®æœç´¢è¯æ•°æ®
    if fw_searchterm is not None and not fw_searchterm.empty:
        print(f"\nğŸ” é£è½®æœç´¢è¯åˆ†æ:")
        print(f"  æ€»æœç´¢è¯æ•°: {len(fw_searchterm)}")

        # æ˜¾ç¤ºåˆ—åä»¥ä¾¿è°ƒè¯•
        print(f"\n  å¯ç”¨åˆ—: {list(fw_searchterm.columns)}")

        # å°è¯•æ‰¾åˆ°èŠ±è´¹ã€é”€å”®ã€ACOSç›¸å…³åˆ—
        cost_cols = [col for col in fw_searchterm.columns if 'èŠ±è´¹' in col or 'cost' in col.lower() or 'æ”¯å‡º' in col]
        sales_cols = [col for col in fw_searchterm.columns if 'é”€å”®' in col or 'sales' in col.lower() or 'æ”¶å…¥' in col]
        acos_cols = [col for col in fw_searchterm.columns if 'ACOS' in col or 'acos' in col.lower()]

        print(f"\n  èŠ±è´¹ç›¸å…³åˆ—: {cost_cols}")
        print(f"  é”€å”®ç›¸å…³åˆ—: {sales_cols}")
        print(f"  ACOSç›¸å…³åˆ—: {acos_cols}")

        # å¦‚æœæœ‰æœç´¢è¯åˆ—ï¼Œæ˜¾ç¤ºå‰å‡ ä¸ª
        keyword_cols = [col for col in fw_searchterm.columns if 'å…³é”®è¯' in col or 'keyword' in col.lower() or 'æœç´¢è¯' in col]
        if keyword_cols:
            print(f"\n  å…³é”®è¯åˆ—: {keyword_cols}")
            print(f"\n  å‰10ä¸ªæœç´¢è¯:")
            print(fw_searchterm[keyword_cols[:1]].head(10).to_string(index=False))

    # åˆ†æé£è½®æŠ•æ”¾æ•°æ®
    if fw_targeting is not None and not fw_targeting.empty:
        print(f"\nğŸ¯ é£è½®æŠ•æ”¾æ•°æ®åˆ†æ:")
        print(f"  æ€»æŠ•æ”¾æ•°: {len(fw_targeting)}")
        print(f"  å¯ç”¨åˆ—: {list(fw_targeting.columns)}")

    # åˆ†æé£è½®å¹¿å‘Šæ´»åŠ¨æ•°æ®
    if fw_campaign is not None and not fw_campaign.empty:
        print(f"\nğŸ“¢ é£è½®å¹¿å‘Šæ´»åŠ¨åˆ†æ:")
        print(f"  æ€»æ´»åŠ¨æ•°: {len(fw_campaign)}")
        print(f"  å¯ç”¨åˆ—: {list(fw_campaign.columns)}")

    return results

def generate_comprehensive_report(all_results):
    """ç”Ÿæˆç»¼åˆä¼˜åŒ–æŠ¥å‘Š"""
    timestamp = datetime.now().strftime("%Y%m%d")
    report_file = REPORTS_DIR / f"TIMO-USå…³é”®è¯ç»´åº¦æ·±åº¦è¯Šæ–­-{timestamp}.md"

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# TIMO ç¾å›½ç«™å…³é”®è¯ç»´åº¦æ·±åº¦è¯Šæ–­æŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        f.write(f"**æ•°æ®æº**: å–å®¶ç²¾çµP2åæŸ¥ + é£è½®3ç»´åº¦ï¼ˆå¹¿å‘Šæ´»åŠ¨/æŠ•æ”¾/æœç´¢è¯ï¼‰\n\n")
        f.write("---\n\n")

        # æ•´ä½“æ‘˜è¦
        f.write("## ğŸ“Š æ•´ä½“æ‘˜è¦\n\n")
        f.write(f"åˆ†æASINæ•°: {len(all_results)}\n\n")

        total_keywords = 0
        total_winner = 0
        total_potential = 0
        total_gap = 0

        for result in all_results:
            if result['sellersprite'] is not None:
                total_keywords += len(result['sellersprite'])
                ss_data = result['sellersprite']
                if 'TES' in ss_data.columns:
                    total_winner += len(ss_data[ss_data['TES'] > 100])
                    total_potential += len(ss_data[(ss_data['TES'] >= 10) & (ss_data['TES'] <= 100)])
                if 'gap_keywords' in result and result['gap_keywords'] is not None:
                    total_gap += len(result['gap_keywords'])

        f.write(f"- **æ€»å…³é”®è¯æ•°**: {total_keywords}\n")
        f.write(f"- **ğŸ† WINNERå…³é”®è¯** (TES>100): {total_winner}ä¸ª\n")
        f.write(f"- **ğŸ’ POTENTIALå…³é”®è¯** (10â‰¤TESâ‰¤100): {total_potential}ä¸ª\n")
        f.write(f"- **ğŸ¯ æµé‡ç¼ºå£è¯** (TES>50 ä¸”æ ‡é¢˜å¯†åº¦<30%): {total_gap}ä¸ª\n\n")

        f.write("---\n\n")

        # æŒ‰ASINè¯¦ç»†åˆ†æ
        for result in all_results:
            asin = result['asin']
            f.write(f"## ASIN: {asin}\n\n")

            # å–å®¶ç²¾çµå…³é”®è¯
            if result['sellersprite'] is not None and 'top_keywords' in result:
                f.write(f"### ğŸ“ˆ Top 10å…³é”®è¯ï¼ˆå–å®¶ç²¾çµP2ï¼‰\n\n")
                f.write("```\n")
                f.write(result['top_keywords'].to_string(index=False))
                f.write("\n```\n\n")

                if 'gap_keywords' in result and result['gap_keywords'] is not None and not result['gap_keywords'].empty:
                    f.write(f"### ğŸ¯ æµé‡ç¼ºå£è¯ï¼ˆä¼˜åŒ–æœºä¼šï¼‰\n\n")
                    f.write("```\n")
                    f.write(result['gap_keywords'][['å…³é”®è¯', 'TES', 'æœˆæœç´¢é‡', 'æ ‡é¢˜å¯†åº¦']].head(10).to_string(index=False))
                    f.write("\n```\n\n")

            f.write("---\n\n")

        # ç»¼åˆä¼˜åŒ–å»ºè®®
        f.write("## ğŸš€ ç»¼åˆä¼˜åŒ–å»ºè®®\n\n")
        f.write("### P0 ç´§æ€¥è¡ŒåŠ¨ï¼ˆDay 1-2ï¼‰\n\n")
        f.write("1. **æ ‡é¢˜ä¼˜åŒ–**ï¼šå°†æµé‡ç¼ºå£è¯åŠ å…¥æ ‡é¢˜ï¼ˆä¼˜å…ˆTES>100çš„WINNERè¯ï¼‰\n")
        f.write("2. **å¹¿å‘ŠæŠ•æ”¾**ï¼šå¯¹WINNERè¯æé«˜ç«ä»·20-30%\n")
        f.write("3. **æ–°å¢å…³é”®è¯**ï¼šå°†POTENTIALè¯åŠ å…¥å¹¿å‘Šç»„\n\n")

        f.write("### P1 ä¸­æœŸä¼˜åŒ–ï¼ˆDay 3-7ï¼‰\n\n")
        f.write("1. **ç›‘æ§ACOS**ï¼šæ–°å¢è¯ACOS>40%åˆ™é™ä»·æˆ–æš‚åœ\n")
        f.write("2. **A+é¡µé¢**ï¼šåœ¨A+é¡µé¢ä¸­åµŒå…¥é«˜TESå…³é”®è¯\n")
        f.write("3. **äº”ç‚¹æè¿°**ï¼šå°†æµé‡ç¼ºå£è¯è‡ªç„¶èå…¥äº§å“æè¿°\n\n")

        f.write("### P2 é•¿æœŸç­–ç•¥ï¼ˆWeek 2+ï¼‰\n\n")
        f.write("1. **æŒç»­ç›‘æ§**ï¼šæ¯å‘¨å¤æŸ¥TESå˜åŒ–ï¼Œè°ƒæ•´ç­–ç•¥\n")
        f.write("2. **ç«å“åˆ†æ**ï¼šå¯¹æ¯”ç«å“æ ‡é¢˜å¯†åº¦ï¼Œå¯»æ‰¾æ–°æœºä¼š\n")
        f.write("3. **æµ‹è¯•è¿­ä»£**ï¼šA/Bæµ‹è¯•ä¸åŒå…³é”®è¯ç»„åˆ\n\n")

    print(f"\nâœ… ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    return report_file

def main():
    print("="*80)
    print("ğŸš€ TIMO ç¾å›½ç«™å…³é”®è¯ç»´åº¦æ·±åº¦åˆ†æ")
    print("="*80)

    all_results = []

    for asin in ASINS:
        result = analyze_asin(asin)
        all_results.append(result)

    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report_file = generate_comprehensive_report(all_results)

    print(f"\n{'='*80}")
    print("âœ… åˆ†æå®Œæˆï¼")
    print(f"{'='*80}")
    print(f"\nğŸ“„ æŠ¥å‘Šä½ç½®: {report_file}")

if __name__ == "__main__":
    main()
